{"cells":[{"cell_type":"markdown","source":["# Group Surveys Feature Determination"],"metadata":{"id":"28sYRJfoFaXt"},"id":"28sYRJfoFaXt"},{"cell_type":"markdown","source":["## Preparation"],"metadata":{"id":"r8p1ntYzFhE0"},"id":"r8p1ntYzFhE0"},{"cell_type":"markdown","source":["### Import"],"metadata":{"id":"1xLE7wUVFjf_"},"id":"1xLE7wUVFjf_"},{"cell_type":"code","execution_count":1,"id":"78992abc","metadata":{"id":"78992abc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685269412650,"user_tz":-120,"elapsed":120912,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"a886c10b-1da2-4c97-a996-326b03007de7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n","import random\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import statsmodels.api as sm\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 1000)"],"metadata":{"id":"1lCVdGaJ1xG3","executionInfo":{"status":"ok","timestamp":1685209808779,"user_tz":-120,"elapsed":9,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"1lCVdGaJ1xG3","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Function Definition"],"metadata":{"id":"oJryoMlhKyjp"},"id":"oJryoMlhKyjp"},{"cell_type":"markdown","source":["### Min-Max Scaler"],"metadata":{"id":"X0_gNbQdt-Ic"},"id":"X0_gNbQdt-Ic"},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","def min_max_scaling_df(df):\n","    scaler = MinMaxScaler()\n","    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n","    return scaled_df\n"],"metadata":{"id":"FI9xDgQMt9lH","executionInfo":{"status":"ok","timestamp":1685209808780,"user_tz":-120,"elapsed":8,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"FI9xDgQMt9lH","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Use of Function"],"metadata":{"id":"UZhXb7j6GErP"},"id":"UZhXb7j6GErP"},{"cell_type":"code","source":["in_file= r'/content/drive/MyDrive/Projects/tps/finals/data/3_individual_features.xlsx'\n","out_file= r'/content/drive/MyDrive/Projects/tps/finals/data/6_model_regression_full_features.xlsx'"],"metadata":{"id":"IXwECopkgaiJ","executionInfo":{"status":"ok","timestamp":1685209808781,"user_tz":-120,"elapsed":8,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"IXwECopkgaiJ","execution_count":4,"outputs":[]},{"cell_type":"code","source":["df= pd.read_excel(in_file, index_col='Id')"],"metadata":{"id":"PsXguzIHvNjp","executionInfo":{"status":"ok","timestamp":1685209809106,"user_tz":-120,"elapsed":333,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"PsXguzIHvNjp","execution_count":5,"outputs":[]},{"cell_type":"code","source":["df.head(12)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"XFCy8EF3NWiT","executionInfo":{"status":"ok","timestamp":1685209809491,"user_tz":-120,"elapsed":388,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"a184aeb9-7a46-4347-fc64-63cfa327d866"},"id":"XFCy8EF3NWiT","execution_count":6,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    indiv_spoken_time  indiv_spoken_time_ratio  average_turn_duration  \\\n","Id                                                                      \n","1                 526                 0.148336               7.850746   \n","2                2648                 0.746757              33.948718   \n","3                 105                 0.029611               8.076923   \n","4                 162                 0.045685               6.480000   \n","5                 105                 0.029611               5.526316   \n","6                1346                 0.337682               8.518987   \n","8                 298                 0.074762              11.461538   \n","9                 697                 0.174862               8.822785   \n","10                276                 0.069242               6.272727   \n","11                266                 0.166562               9.851852   \n","12                206                 0.128992               5.567568   \n","13                 21                 0.013150               3.000000   \n","\n","    average_turn_duration_ratio  avg_time_without_speaking  \\\n","Id                                                           \n","1                      0.126865                  56.210746   \n","2                      0.548598                  21.791169   \n","3                      0.130520                  57.649231   \n","4                      0.104714                 159.421600   \n","5                      0.089303                  43.632632   \n","6                      0.185779                  19.887848   \n","8                      0.249949                 162.167200   \n","9                      0.192404                  47.935696   \n","10                     0.136793                  25.912727   \n","11                     0.207658                  95.963077   \n","12                     0.117353                  67.669189   \n","13                     0.063234                 385.191429   \n","\n","    avg_time_without_speaking_ratio  max_time_without_speaking  \\\n","Id                                                               \n","1                          0.165958                     451.54   \n","2                          0.064337                     109.24   \n","3                          0.170205                     141.72   \n","4                          0.470679                     836.46   \n","5                          0.128822                     169.20   \n","6                          0.070957                     169.82   \n","8                          0.578592                    1529.54   \n","9                          0.171028                    1421.86   \n","10                         0.092453                     218.84   \n","11                         0.123819                    1446.52   \n","12                         0.087312                    1046.36   \n","13                         0.497002                    1465.98   \n","\n","    max_time_without_speaking_ratio  num_turns  num_turns_ratio  \\\n","Id                                                                \n","1                          0.264343         67         0.331683   \n","2                          0.063952         78         0.386139   \n","3                          0.082966         13         0.064356   \n","4                          0.489685         25         0.123762   \n","5                          0.099054         19         0.094059   \n","6                          0.044430        158         0.364055   \n","8                          0.400177         26         0.059908   \n","9                          0.372004         79         0.182028   \n","10                         0.057256         44         0.101382   \n","11                         0.226016         27         0.174194   \n","12                         0.163492         37         0.238710   \n","13                         0.229057          7         0.045161   \n","\n","    avg_turns_without_speaking  avg_turns_without_speaking_ratio  \\\n","Id                                                                 \n","1                     1.985075                          0.093801   \n","2                     1.589744                          0.075120   \n","3                     6.461538                          0.305327   \n","4                     6.600000                          0.311870   \n","5                     4.526316                          0.213882   \n","6                     1.740506                          0.064235   \n","8                    15.384615                          0.567781   \n","9                     4.455696                          0.164441   \n","10                    3.113636                          0.114911   \n","11                    4.740741                          0.115024   \n","12                    3.054054                          0.074100   \n","13                   20.285714                          0.492190   \n","\n","    max_turns_without_speaking  max_turns_without_speaking_ratio  num_words  \\\n","Id                                                                            \n","1                            7                          0.090909        978   \n","2                            9                          0.116883       3816   \n","3                           15                          0.194805        267   \n","4                           29                          0.376623        394   \n","5                           17                          0.220779        271   \n","6                            9                          0.028846       4025   \n","8                          125                          0.400641        764   \n","9                          108                          0.346154       2062   \n","10                          24                          0.076923        857   \n","11                          40                          0.242424        543   \n","12                          11                          0.066667        547   \n","13                          50                          0.303030         53   \n","\n","    num_words_ratio  avg_words_turn  avg_words_turn_ratio  max_words_turn  \\\n","Id                                                                          \n","1          0.170800       14.597015              0.127952              68   \n","2          0.666434       48.923077              0.428842             623   \n","3          0.046629       20.538462              0.180033              70   \n","4          0.068809       15.760000              0.138147              61   \n","5          0.047328       14.263158              0.125026              43   \n","6          0.329109       25.474684              0.187253             230   \n","8          0.062469       29.384615              0.215993             167   \n","9          0.168602       26.101266              0.191859             257   \n","10         0.070074       19.477273              0.143169              78   \n","11         0.164945       20.111111              0.200261              83   \n","12         0.166160       14.783784              0.147213              38   \n","13         0.016100        7.571429              0.075394              16   \n","\n","    max_words_turn_ratio  speech_neu  speech_ang  speech_hap  speech_sad  \\\n","Id                                                                         \n","1               0.078613    0.832695    0.137502    0.026347    0.003456   \n","2               0.720231    0.795958    0.155654    0.045315    0.003074   \n","3               0.080925    0.789103    0.161515    0.037497    0.011885   \n","4               0.070520    0.712697    0.196289    0.077861    0.013153   \n","5               0.049711    0.746439    0.193365    0.054215    0.005981   \n","6               0.233503    0.768060    0.181860    0.043375    0.006704   \n","8               0.169543    0.782264    0.203949    0.012210    0.001577   \n","9               0.260914    0.735439    0.228609    0.030550    0.005402   \n","10              0.079188    0.710042    0.214038    0.066733    0.009187   \n","11              0.166000    0.850650    0.140287    0.007156    0.001907   \n","12              0.076000    0.859285    0.132217    0.008067    0.000432   \n","13              0.032000    0.842470    0.148914    0.008367    0.000250   \n","\n","    text_joy  text_anger  text_fear  text_sadness  messages_sent  \\\n","Id                                                                 \n","1   0.298809    0.236814   0.232361      0.232015             34   \n","2   0.292950    0.239695   0.227768      0.239587             75   \n","3   0.297727    0.238513   0.230916      0.232844             38   \n","4   0.300100    0.235307   0.232877      0.231716             27   \n","5   0.303593    0.235377   0.233832      0.227198             22   \n","6   0.297780    0.237582   0.227811      0.236827             22   \n","8   0.300151    0.233183   0.230322      0.236344              8   \n","9   0.295444    0.239446   0.225465      0.239646              8   \n","10  0.298211    0.236990   0.226584      0.238215             24   \n","11  0.268266    0.257794   0.243564      0.230376              9   \n","12  0.258766    0.265813   0.243549      0.231872             14   \n","13  0.260389    0.269587   0.246609      0.223415              5   \n","\n","    messages_total  contribution_index        ego_art     ego_nudges  \\\n","Id                                                                     \n","1              187               -0.64  1.332.855.889  2.468.578.279   \n","2              228               -0.34  7.778.626.875  1.363.151.848   \n","3              191               -0.60  1.006.371.139  2.010.089.278   \n","4              180               -0.70  1.197.692.111  2.333.088.249   \n","5              175               -0.75  8.437.013.889  2.777.083.337   \n","6               69               -0.36  1.326.435.903  1.628.846.139   \n","8               55               -0.71  3.302.708.333  3.037.500.024   \n","9               55               -0.71  2.095.583.333  3.866.666.635   \n","10              71               -0.32  1.213.291.667  1.720.833.361   \n","11              60               -0.70  4.099.444.444  2.966.666.698   \n","12              65               -0.57  2.239.142.833  1.705.714.297   \n","13              56               -0.82  1.414.444.444  1.316.666.675   \n","\n","        alter_art   alter_nudges  sentiment_avg  emotionality_avg  \\\n","Id                                                                  \n","1   1.234.255.833  1.903.921.545       0.303561          0.215562   \n","2   9.695.611.111  3.791.190.505       0.250396          0.236507   \n","3   9.903.272.639  2.270.121.068       0.381860          0.254014   \n","4   7.537.312.014  1.568.276.525       0.250852          0.259828   \n","5   1.210.607.806    141.848.135       0.305600          0.244289   \n","6   5.609.305.556  4.304.166.675       0.404612          0.268756   \n","8   1.476.083.333  2.912.499.994       0.746794          0.579783   \n","9   1.623.819.444  2.291.666.687       0.428550          0.236425   \n","10  9.400.256.481    287.179.486       0.259263          0.253813   \n","11  1.503.222.222    200.999.999       0.417330          0.146854   \n","12  2.081.333.333  2.793.333.387       0.374595          0.214163   \n","13    0.266666667  1.533.333.325       0.397734          0.225812   \n","\n","   complexity_avg influence_message_avg influence_total_in  \\\n","Id                                                           \n","1   9.179.501.577           0.346125353      1.227.594.788   \n","2   9.308.010.889           0.428515776        0.997035569   \n","3   9.034.121.152           0.236068168        0.866593847   \n","4   9.557.120.015           0.486946776      2.016.371.149   \n","5     870.027.021            0.36035958        178.005.748   \n","6   8.831.858.439           0.275771772        0.030908656   \n","8     988.272.047                     0        0.959899291   \n","9   9.147.384.644           0.061817313        0.254338987   \n","10  9.067.036.629            0.03761133        0.098445511   \n","11    867.734.657           0.900596442        0.174141428   \n","12    994.641.037           0.159374716      1.422.213.784   \n","13  1.037.045.288           0.057181978         0.35519399   \n","\n","   influence_message_avg_in influence_total  contribution_index_oscillation  \\\n","Id                                                                            \n","1               0.346135338   1.730.626.767                               1   \n","2               0.231981331   1.988.107.685                               2   \n","3               0.199153824     103.894.739                               2   \n","4               0.467754404   1.159.895.116                               2   \n","5               0.421674039     0.970075875                               1   \n","6               0.030908656     0.412769952                               4   \n","8               0.959899291               0                               4   \n","9               0.127169494     0.061817313                               1   \n","10              0.098445511      0.03761133                               3   \n","11              0.080865228     224.194.098                               4   \n","12              0.673765582     0.441292182                               5   \n","13              0.237660702     0.057181978                               4   \n","\n","    activity_entanglement  ALTERNATIVE_REALITIES_Treehugger  \\\n","Id                                                            \n","1                0.487649                          0.472084   \n","2                0.398994                          0.438515   \n","3                0.501416                          0.157377   \n","4                0.493443                          0.258578   \n","5                0.555323                          0.362543   \n","6                0.520000                          0.362597   \n","8                0.529475                          0.029491   \n","9                0.518237                          0.249223   \n","10               0.497027                          0.193271   \n","11               0.547170                          0.443086   \n","12               0.532976                          0.083002   \n","13               0.540482                          0.398627   \n","\n","    ALTERNATIVE_REALITIES_Fatherlander  ALTERNATIVE_REALITIES_Spiritualism  \\\n","Id                                                                           \n","1                             0.083889                            0.089140   \n","2                             0.040232                            0.107725   \n","3                             0.028980                            0.053947   \n","4                             0.073231                            0.112001   \n","5                             0.000314                            0.136496   \n","6                             0.134296                            0.001890   \n","8                             0.125285                            0.000506   \n","9                             0.057101                            0.193481   \n","10                            0.038510                            0.087476   \n","11                            0.000356                            0.333701   \n","12                            0.016628                            0.144063   \n","13                            0.000415                            0.000592   \n","\n","    ALTERNATIVE_REALITIES_Nerd  EMOTIONS_Fear  EMOTIONS_Happy  EMOTIONS_Sad  \\\n","Id                                                                            \n","1                     0.354886       0.236101        0.407447      0.251288   \n","2                     0.413528       0.215535        0.417419      0.208064   \n","3                     0.759697       0.245048        0.410218      0.190879   \n","4                     0.556190       0.319698        0.322770      0.225624   \n","5                     0.500648       0.157227        0.472688      0.321906   \n","6                     0.501216       0.152454        0.624326      0.145505   \n","8                     0.844718       0.121923        0.685490      0.083875   \n","9                     0.500194       0.070225        0.553516      0.309070   \n","10                    0.680743       0.150721        0.602558      0.153305   \n","11                    0.222857       0.290449        0.443599      0.177075   \n","12                    0.756307       0.152018        0.409034      0.171133   \n","13                    0.600366       0.033830        0.774783      0.176173   \n","\n","    EMOTIONS_Anger  Groupflow_Beeflow  Groupflow_Leechflow  Groupflow_Antflow  \\\n","Id                                                                              \n","1         0.105165           0.497477             0.156358           0.346165   \n","2         0.158982           0.300955             0.220056           0.478989   \n","3         0.153855           0.226931             0.238211           0.534858   \n","4         0.131909           0.256794             0.232465           0.510740   \n","5         0.048179           0.342162             0.120088           0.537751   \n","6         0.077715           0.332323             0.221886           0.445791   \n","8         0.108711           0.535406             0.037475           0.427119   \n","9         0.067189           0.065323             0.311680           0.622997   \n","10        0.093417           0.221334             0.277272           0.501394   \n","11        0.088877           0.399318             0.391894           0.208788   \n","12        0.267815           0.299807             0.324159           0.376034   \n","13        0.015214           0.004723             0.383587           0.611690   \n","\n","    ethical_likelihood  financial_likelihood  health_likelihood  \\\n","Id                                                                \n","1             4.500000              3.500000           4.166667   \n","2             2.000000              1.500000           1.000000   \n","3             4.500000              3.500000           2.666667   \n","4             2.166667              1.500000           1.000000   \n","5             3.166667              2.666667           3.500000   \n","6             1.833333              3.833333           3.666667   \n","8             4.666667              3.666667           4.333333   \n","9             3.000000              2.666667           3.166667   \n","10            1.500000              2.000000           1.333333   \n","11            1.666667              5.666667           3.166667   \n","12            1.500000              1.333333           2.666667   \n","13            3.500000              4.333333           3.166667   \n","\n","    recreational_likelihood  social_likelihood  total_likelihood  \\\n","Id                                                                 \n","1                  3.166667           3.500000          3.766667   \n","2                  5.166667           5.500000          3.033333   \n","3                  6.000000           6.000000          4.533333   \n","4                  4.166667           4.833333          2.733333   \n","5                  5.166667           3.666667          3.633333   \n","6                  6.166667           5.500000          4.200000   \n","8                  4.500000           4.666667          4.366667   \n","9                  5.000000           5.000000          3.766667   \n","10                 3.166667           5.000000          2.600000   \n","11                 6.500000           5.000000          4.400000   \n","12                 1.333333           5.333333          2.433333   \n","13                 3.166667           4.666667          3.766667   \n","\n","    ethical_perceived  financial_perceived  health_perceived  \\\n","Id                                                             \n","1            4.833333             5.666667          5.666667   \n","2            4.000000             6.666667          6.500000   \n","3            5.000000             5.500000          5.500000   \n","4            5.833333             6.000000          6.333333   \n","5            3.666667             5.833333          3.666667   \n","6            3.500000             4.000000          6.333333   \n","8            3.666667             4.833333          6.000000   \n","9            3.666667             5.833333          4.333333   \n","10           5.333333             4.500000          6.166667   \n","11           6.666667             4.166667          6.000000   \n","12           3.666667             3.833333          6.000000   \n","13           3.833333             3.000000          3.833333   \n","\n","    recreational_perceived  social_perceived  total_perceived         O  \\\n","Id                                                                        \n","1                 5.833333          4.833333                5  0.600000   \n","2                 5.500000          3.000000                5  0.533333   \n","3                 4.333333          2.833333                5  0.566667   \n","4                 5.000000          4.166667                5  0.566667   \n","5                 3.000000          3.666667                4  0.600000   \n","6                 4.333333          2.833333                4  0.683333   \n","8                 5.333333          4.333333                5  0.533333   \n","9                 3.000000          2.833333                4  0.616667   \n","10                5.500000          3.166667                5  0.533333   \n","11                4.666667          4.000000                5  0.583333   \n","12                5.666667          2.833333                4  0.566667   \n","13                3.500000          2.333333                3  0.600000   \n","\n","           C         E         A         N  harm_care_score  \\\n","Id                                                            \n","1   0.716667  0.600000  0.633333  0.583333               27   \n","2   0.666667  0.700000  0.616667  0.633333               22   \n","3   0.683333  0.716667  0.533333  0.716667               23   \n","4   0.783333  0.733333  0.733333  0.633333               17   \n","5   0.666667  0.483333  0.583333  0.433333               12   \n","6   0.733333  0.883333  0.583333  0.416667               24   \n","8   0.683333  0.716667  0.500000  0.516667               28   \n","9   0.700000  0.716667  0.716667  0.550000               17   \n","10  0.700000  0.583333  0.550000  0.583333               27   \n","11  0.733333  0.616667  0.650000  0.383333               23   \n","12  0.716667  0.583333  0.616667  0.583333               20   \n","13  0.666667  0.633333  0.650000  0.466667               25   \n","\n","    fairness_reciprocity_score  in_group_loyality_score  \\\n","Id                                                        \n","1                           23                       19   \n","2                           28                       11   \n","3                           28                        9   \n","4                           24                       17   \n","5                           15                       11   \n","6                           26                       13   \n","8                           20                       21   \n","9                           23                       16   \n","10                          26                       18   \n","11                          23                       20   \n","12                          25                       15   \n","13                          21                       17   \n","\n","    authority_respect_score  purity_sanctity_score  dummy_question1  \\\n","Id                                                                    \n","1                        18                     20                1   \n","2                         7                     11                0   \n","3                         6                      7                1   \n","4                        13                      8                3   \n","5                        19                      4                0   \n","6                        13                     15                1   \n","8                        23                     24                3   \n","9                        13                     14                2   \n","10                       18                     18                0   \n","11                       23                     18                1   \n","12                       13                     12                2   \n","13                       15                     18                2   \n","\n","    dummy_question2  q1  q2  q3  q4  q5  q6  q7  q8  q9  q10  conservation  \\\n","Id                                                                           \n","1                 5   7   6   5   7   5   4   5   7   8    7          2.57   \n","2                 5   2   6   4   4   7   8   8   0   5    4         -0.24   \n","3                 5   6   7   6   8   8   8   6   3   2    6         -0.52   \n","4                 4   6   7   7   6   7   6   6   2   4    7          0.42   \n","5                 3   6   4   4   3   8   4   4   1   5    7          0.73   \n","6                 5   6   7   7   6   5   8   8   3   4    4          0.38   \n","8                 3   4   6   5   4   6   4   5   4   6    8          1.77   \n","9                 4   6   7   6   4   4   3   6   2   6    4          1.72   \n","10                5   3   5   4   3   4   8   8   3   3    8          0.90   \n","11                5   6   7   5   7   8   8   6   2   6    6          0.17   \n","12                5   6   7   4   3   8   4   8   4   5    6          1.41   \n","13                5   8   8   8   4   7   4   6   7   6    7          2.20   \n","\n","    transcendence  theory  coeval  project  \n","Id                                          \n","1           -1.78    3.44    0.90      8.0  \n","2           -0.33    3.64    0.91      8.0  \n","3           -2.03    3.98    0.90      8.0  \n","4           -2.04    4.22    0.90      8.0  \n","5           -1.48    3.74    0.91      8.0  \n","6           -1.59    4.64    0.78      8.5  \n","8           -1.18    3.61    0.78      8.5  \n","9           -2.00    4.37    0.77      8.5  \n","10          -0.13    5.33    0.90      8.5  \n","11          -1.66    5.57    0.91      8.0  \n","12          -1.19    5.05    0.93      8.0  \n","13          -2.16    4.60    0.91      8.0  "],"text/html":["\n","  <div id=\"df-4a567e6d-881b-4776-b0f7-7cc1aa895057\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>indiv_spoken_time</th>\n","      <th>indiv_spoken_time_ratio</th>\n","      <th>average_turn_duration</th>\n","      <th>average_turn_duration_ratio</th>\n","      <th>avg_time_without_speaking</th>\n","      <th>avg_time_without_speaking_ratio</th>\n","      <th>max_time_without_speaking</th>\n","      <th>max_time_without_speaking_ratio</th>\n","      <th>num_turns</th>\n","      <th>num_turns_ratio</th>\n","      <th>avg_turns_without_speaking</th>\n","      <th>avg_turns_without_speaking_ratio</th>\n","      <th>max_turns_without_speaking</th>\n","      <th>max_turns_without_speaking_ratio</th>\n","      <th>num_words</th>\n","      <th>num_words_ratio</th>\n","      <th>avg_words_turn</th>\n","      <th>avg_words_turn_ratio</th>\n","      <th>max_words_turn</th>\n","      <th>max_words_turn_ratio</th>\n","      <th>speech_neu</th>\n","      <th>speech_ang</th>\n","      <th>speech_hap</th>\n","      <th>speech_sad</th>\n","      <th>text_joy</th>\n","      <th>text_anger</th>\n","      <th>text_fear</th>\n","      <th>text_sadness</th>\n","      <th>messages_sent</th>\n","      <th>messages_total</th>\n","      <th>contribution_index</th>\n","      <th>ego_art</th>\n","      <th>ego_nudges</th>\n","      <th>alter_art</th>\n","      <th>alter_nudges</th>\n","      <th>sentiment_avg</th>\n","      <th>emotionality_avg</th>\n","      <th>complexity_avg</th>\n","      <th>influence_message_avg</th>\n","      <th>influence_total_in</th>\n","      <th>influence_message_avg_in</th>\n","      <th>influence_total</th>\n","      <th>contribution_index_oscillation</th>\n","      <th>activity_entanglement</th>\n","      <th>ALTERNATIVE_REALITIES_Treehugger</th>\n","      <th>ALTERNATIVE_REALITIES_Fatherlander</th>\n","      <th>ALTERNATIVE_REALITIES_Spiritualism</th>\n","      <th>ALTERNATIVE_REALITIES_Nerd</th>\n","      <th>EMOTIONS_Fear</th>\n","      <th>EMOTIONS_Happy</th>\n","      <th>EMOTIONS_Sad</th>\n","      <th>EMOTIONS_Anger</th>\n","      <th>Groupflow_Beeflow</th>\n","      <th>Groupflow_Leechflow</th>\n","      <th>Groupflow_Antflow</th>\n","      <th>ethical_likelihood</th>\n","      <th>financial_likelihood</th>\n","      <th>health_likelihood</th>\n","      <th>recreational_likelihood</th>\n","      <th>social_likelihood</th>\n","      <th>total_likelihood</th>\n","      <th>ethical_perceived</th>\n","      <th>financial_perceived</th>\n","      <th>health_perceived</th>\n","      <th>recreational_perceived</th>\n","      <th>social_perceived</th>\n","      <th>total_perceived</th>\n","      <th>O</th>\n","      <th>C</th>\n","      <th>E</th>\n","      <th>A</th>\n","      <th>N</th>\n","      <th>harm_care_score</th>\n","      <th>fairness_reciprocity_score</th>\n","      <th>in_group_loyality_score</th>\n","      <th>authority_respect_score</th>\n","      <th>purity_sanctity_score</th>\n","      <th>dummy_question1</th>\n","      <th>dummy_question2</th>\n","      <th>q1</th>\n","      <th>q2</th>\n","      <th>q3</th>\n","      <th>q4</th>\n","      <th>q5</th>\n","      <th>q6</th>\n","      <th>q7</th>\n","      <th>q8</th>\n","      <th>q9</th>\n","      <th>q10</th>\n","      <th>conservation</th>\n","      <th>transcendence</th>\n","      <th>theory</th>\n","      <th>coeval</th>\n","      <th>project</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>526</td>\n","      <td>0.148336</td>\n","      <td>7.850746</td>\n","      <td>0.126865</td>\n","      <td>56.210746</td>\n","      <td>0.165958</td>\n","      <td>451.54</td>\n","      <td>0.264343</td>\n","      <td>67</td>\n","      <td>0.331683</td>\n","      <td>1.985075</td>\n","      <td>0.093801</td>\n","      <td>7</td>\n","      <td>0.090909</td>\n","      <td>978</td>\n","      <td>0.170800</td>\n","      <td>14.597015</td>\n","      <td>0.127952</td>\n","      <td>68</td>\n","      <td>0.078613</td>\n","      <td>0.832695</td>\n","      <td>0.137502</td>\n","      <td>0.026347</td>\n","      <td>0.003456</td>\n","      <td>0.298809</td>\n","      <td>0.236814</td>\n","      <td>0.232361</td>\n","      <td>0.232015</td>\n","      <td>34</td>\n","      <td>187</td>\n","      <td>-0.64</td>\n","      <td>1.332.855.889</td>\n","      <td>2.468.578.279</td>\n","      <td>1.234.255.833</td>\n","      <td>1.903.921.545</td>\n","      <td>0.303561</td>\n","      <td>0.215562</td>\n","      <td>9.179.501.577</td>\n","      <td>0.346125353</td>\n","      <td>1.227.594.788</td>\n","      <td>0.346135338</td>\n","      <td>1.730.626.767</td>\n","      <td>1</td>\n","      <td>0.487649</td>\n","      <td>0.472084</td>\n","      <td>0.083889</td>\n","      <td>0.089140</td>\n","      <td>0.354886</td>\n","      <td>0.236101</td>\n","      <td>0.407447</td>\n","      <td>0.251288</td>\n","      <td>0.105165</td>\n","      <td>0.497477</td>\n","      <td>0.156358</td>\n","      <td>0.346165</td>\n","      <td>4.500000</td>\n","      <td>3.500000</td>\n","      <td>4.166667</td>\n","      <td>3.166667</td>\n","      <td>3.500000</td>\n","      <td>3.766667</td>\n","      <td>4.833333</td>\n","      <td>5.666667</td>\n","      <td>5.666667</td>\n","      <td>5.833333</td>\n","      <td>4.833333</td>\n","      <td>5</td>\n","      <td>0.600000</td>\n","      <td>0.716667</td>\n","      <td>0.600000</td>\n","      <td>0.633333</td>\n","      <td>0.583333</td>\n","      <td>27</td>\n","      <td>23</td>\n","      <td>19</td>\n","      <td>18</td>\n","      <td>20</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>7</td>\n","      <td>2.57</td>\n","      <td>-1.78</td>\n","      <td>3.44</td>\n","      <td>0.90</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2648</td>\n","      <td>0.746757</td>\n","      <td>33.948718</td>\n","      <td>0.548598</td>\n","      <td>21.791169</td>\n","      <td>0.064337</td>\n","      <td>109.24</td>\n","      <td>0.063952</td>\n","      <td>78</td>\n","      <td>0.386139</td>\n","      <td>1.589744</td>\n","      <td>0.075120</td>\n","      <td>9</td>\n","      <td>0.116883</td>\n","      <td>3816</td>\n","      <td>0.666434</td>\n","      <td>48.923077</td>\n","      <td>0.428842</td>\n","      <td>623</td>\n","      <td>0.720231</td>\n","      <td>0.795958</td>\n","      <td>0.155654</td>\n","      <td>0.045315</td>\n","      <td>0.003074</td>\n","      <td>0.292950</td>\n","      <td>0.239695</td>\n","      <td>0.227768</td>\n","      <td>0.239587</td>\n","      <td>75</td>\n","      <td>228</td>\n","      <td>-0.34</td>\n","      <td>7.778.626.875</td>\n","      <td>1.363.151.848</td>\n","      <td>9.695.611.111</td>\n","      <td>3.791.190.505</td>\n","      <td>0.250396</td>\n","      <td>0.236507</td>\n","      <td>9.308.010.889</td>\n","      <td>0.428515776</td>\n","      <td>0.997035569</td>\n","      <td>0.231981331</td>\n","      <td>1.988.107.685</td>\n","      <td>2</td>\n","      <td>0.398994</td>\n","      <td>0.438515</td>\n","      <td>0.040232</td>\n","      <td>0.107725</td>\n","      <td>0.413528</td>\n","      <td>0.215535</td>\n","      <td>0.417419</td>\n","      <td>0.208064</td>\n","      <td>0.158982</td>\n","      <td>0.300955</td>\n","      <td>0.220056</td>\n","      <td>0.478989</td>\n","      <td>2.000000</td>\n","      <td>1.500000</td>\n","      <td>1.000000</td>\n","      <td>5.166667</td>\n","      <td>5.500000</td>\n","      <td>3.033333</td>\n","      <td>4.000000</td>\n","      <td>6.666667</td>\n","      <td>6.500000</td>\n","      <td>5.500000</td>\n","      <td>3.000000</td>\n","      <td>5</td>\n","      <td>0.533333</td>\n","      <td>0.666667</td>\n","      <td>0.700000</td>\n","      <td>0.616667</td>\n","      <td>0.633333</td>\n","      <td>22</td>\n","      <td>28</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>11</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>-0.24</td>\n","      <td>-0.33</td>\n","      <td>3.64</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>105</td>\n","      <td>0.029611</td>\n","      <td>8.076923</td>\n","      <td>0.130520</td>\n","      <td>57.649231</td>\n","      <td>0.170205</td>\n","      <td>141.72</td>\n","      <td>0.082966</td>\n","      <td>13</td>\n","      <td>0.064356</td>\n","      <td>6.461538</td>\n","      <td>0.305327</td>\n","      <td>15</td>\n","      <td>0.194805</td>\n","      <td>267</td>\n","      <td>0.046629</td>\n","      <td>20.538462</td>\n","      <td>0.180033</td>\n","      <td>70</td>\n","      <td>0.080925</td>\n","      <td>0.789103</td>\n","      <td>0.161515</td>\n","      <td>0.037497</td>\n","      <td>0.011885</td>\n","      <td>0.297727</td>\n","      <td>0.238513</td>\n","      <td>0.230916</td>\n","      <td>0.232844</td>\n","      <td>38</td>\n","      <td>191</td>\n","      <td>-0.60</td>\n","      <td>1.006.371.139</td>\n","      <td>2.010.089.278</td>\n","      <td>9.903.272.639</td>\n","      <td>2.270.121.068</td>\n","      <td>0.381860</td>\n","      <td>0.254014</td>\n","      <td>9.034.121.152</td>\n","      <td>0.236068168</td>\n","      <td>0.866593847</td>\n","      <td>0.199153824</td>\n","      <td>103.894.739</td>\n","      <td>2</td>\n","      <td>0.501416</td>\n","      <td>0.157377</td>\n","      <td>0.028980</td>\n","      <td>0.053947</td>\n","      <td>0.759697</td>\n","      <td>0.245048</td>\n","      <td>0.410218</td>\n","      <td>0.190879</td>\n","      <td>0.153855</td>\n","      <td>0.226931</td>\n","      <td>0.238211</td>\n","      <td>0.534858</td>\n","      <td>4.500000</td>\n","      <td>3.500000</td>\n","      <td>2.666667</td>\n","      <td>6.000000</td>\n","      <td>6.000000</td>\n","      <td>4.533333</td>\n","      <td>5.000000</td>\n","      <td>5.500000</td>\n","      <td>5.500000</td>\n","      <td>4.333333</td>\n","      <td>2.833333</td>\n","      <td>5</td>\n","      <td>0.566667</td>\n","      <td>0.683333</td>\n","      <td>0.716667</td>\n","      <td>0.533333</td>\n","      <td>0.716667</td>\n","      <td>23</td>\n","      <td>28</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>-0.52</td>\n","      <td>-2.03</td>\n","      <td>3.98</td>\n","      <td>0.90</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>162</td>\n","      <td>0.045685</td>\n","      <td>6.480000</td>\n","      <td>0.104714</td>\n","      <td>159.421600</td>\n","      <td>0.470679</td>\n","      <td>836.46</td>\n","      <td>0.489685</td>\n","      <td>25</td>\n","      <td>0.123762</td>\n","      <td>6.600000</td>\n","      <td>0.311870</td>\n","      <td>29</td>\n","      <td>0.376623</td>\n","      <td>394</td>\n","      <td>0.068809</td>\n","      <td>15.760000</td>\n","      <td>0.138147</td>\n","      <td>61</td>\n","      <td>0.070520</td>\n","      <td>0.712697</td>\n","      <td>0.196289</td>\n","      <td>0.077861</td>\n","      <td>0.013153</td>\n","      <td>0.300100</td>\n","      <td>0.235307</td>\n","      <td>0.232877</td>\n","      <td>0.231716</td>\n","      <td>27</td>\n","      <td>180</td>\n","      <td>-0.70</td>\n","      <td>1.197.692.111</td>\n","      <td>2.333.088.249</td>\n","      <td>7.537.312.014</td>\n","      <td>1.568.276.525</td>\n","      <td>0.250852</td>\n","      <td>0.259828</td>\n","      <td>9.557.120.015</td>\n","      <td>0.486946776</td>\n","      <td>2.016.371.149</td>\n","      <td>0.467754404</td>\n","      <td>1.159.895.116</td>\n","      <td>2</td>\n","      <td>0.493443</td>\n","      <td>0.258578</td>\n","      <td>0.073231</td>\n","      <td>0.112001</td>\n","      <td>0.556190</td>\n","      <td>0.319698</td>\n","      <td>0.322770</td>\n","      <td>0.225624</td>\n","      <td>0.131909</td>\n","      <td>0.256794</td>\n","      <td>0.232465</td>\n","      <td>0.510740</td>\n","      <td>2.166667</td>\n","      <td>1.500000</td>\n","      <td>1.000000</td>\n","      <td>4.166667</td>\n","      <td>4.833333</td>\n","      <td>2.733333</td>\n","      <td>5.833333</td>\n","      <td>6.000000</td>\n","      <td>6.333333</td>\n","      <td>5.000000</td>\n","      <td>4.166667</td>\n","      <td>5</td>\n","      <td>0.566667</td>\n","      <td>0.783333</td>\n","      <td>0.733333</td>\n","      <td>0.733333</td>\n","      <td>0.633333</td>\n","      <td>17</td>\n","      <td>24</td>\n","      <td>17</td>\n","      <td>13</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>0.42</td>\n","      <td>-2.04</td>\n","      <td>4.22</td>\n","      <td>0.90</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>105</td>\n","      <td>0.029611</td>\n","      <td>5.526316</td>\n","      <td>0.089303</td>\n","      <td>43.632632</td>\n","      <td>0.128822</td>\n","      <td>169.20</td>\n","      <td>0.099054</td>\n","      <td>19</td>\n","      <td>0.094059</td>\n","      <td>4.526316</td>\n","      <td>0.213882</td>\n","      <td>17</td>\n","      <td>0.220779</td>\n","      <td>271</td>\n","      <td>0.047328</td>\n","      <td>14.263158</td>\n","      <td>0.125026</td>\n","      <td>43</td>\n","      <td>0.049711</td>\n","      <td>0.746439</td>\n","      <td>0.193365</td>\n","      <td>0.054215</td>\n","      <td>0.005981</td>\n","      <td>0.303593</td>\n","      <td>0.235377</td>\n","      <td>0.233832</td>\n","      <td>0.227198</td>\n","      <td>22</td>\n","      <td>175</td>\n","      <td>-0.75</td>\n","      <td>8.437.013.889</td>\n","      <td>2.777.083.337</td>\n","      <td>1.210.607.806</td>\n","      <td>141.848.135</td>\n","      <td>0.305600</td>\n","      <td>0.244289</td>\n","      <td>870.027.021</td>\n","      <td>0.36035958</td>\n","      <td>178.005.748</td>\n","      <td>0.421674039</td>\n","      <td>0.970075875</td>\n","      <td>1</td>\n","      <td>0.555323</td>\n","      <td>0.362543</td>\n","      <td>0.000314</td>\n","      <td>0.136496</td>\n","      <td>0.500648</td>\n","      <td>0.157227</td>\n","      <td>0.472688</td>\n","      <td>0.321906</td>\n","      <td>0.048179</td>\n","      <td>0.342162</td>\n","      <td>0.120088</td>\n","      <td>0.537751</td>\n","      <td>3.166667</td>\n","      <td>2.666667</td>\n","      <td>3.500000</td>\n","      <td>5.166667</td>\n","      <td>3.666667</td>\n","      <td>3.633333</td>\n","      <td>3.666667</td>\n","      <td>5.833333</td>\n","      <td>3.666667</td>\n","      <td>3.000000</td>\n","      <td>3.666667</td>\n","      <td>4</td>\n","      <td>0.600000</td>\n","      <td>0.666667</td>\n","      <td>0.483333</td>\n","      <td>0.583333</td>\n","      <td>0.433333</td>\n","      <td>12</td>\n","      <td>15</td>\n","      <td>11</td>\n","      <td>19</td>\n","      <td>4</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>0.73</td>\n","      <td>-1.48</td>\n","      <td>3.74</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>1346</td>\n","      <td>0.337682</td>\n","      <td>8.518987</td>\n","      <td>0.185779</td>\n","      <td>19.887848</td>\n","      <td>0.070957</td>\n","      <td>169.82</td>\n","      <td>0.044430</td>\n","      <td>158</td>\n","      <td>0.364055</td>\n","      <td>1.740506</td>\n","      <td>0.064235</td>\n","      <td>9</td>\n","      <td>0.028846</td>\n","      <td>4025</td>\n","      <td>0.329109</td>\n","      <td>25.474684</td>\n","      <td>0.187253</td>\n","      <td>230</td>\n","      <td>0.233503</td>\n","      <td>0.768060</td>\n","      <td>0.181860</td>\n","      <td>0.043375</td>\n","      <td>0.006704</td>\n","      <td>0.297780</td>\n","      <td>0.237582</td>\n","      <td>0.227811</td>\n","      <td>0.236827</td>\n","      <td>22</td>\n","      <td>69</td>\n","      <td>-0.36</td>\n","      <td>1.326.435.903</td>\n","      <td>1.628.846.139</td>\n","      <td>5.609.305.556</td>\n","      <td>4.304.166.675</td>\n","      <td>0.404612</td>\n","      <td>0.268756</td>\n","      <td>8.831.858.439</td>\n","      <td>0.275771772</td>\n","      <td>0.030908656</td>\n","      <td>0.030908656</td>\n","      <td>0.412769952</td>\n","      <td>4</td>\n","      <td>0.520000</td>\n","      <td>0.362597</td>\n","      <td>0.134296</td>\n","      <td>0.001890</td>\n","      <td>0.501216</td>\n","      <td>0.152454</td>\n","      <td>0.624326</td>\n","      <td>0.145505</td>\n","      <td>0.077715</td>\n","      <td>0.332323</td>\n","      <td>0.221886</td>\n","      <td>0.445791</td>\n","      <td>1.833333</td>\n","      <td>3.833333</td>\n","      <td>3.666667</td>\n","      <td>6.166667</td>\n","      <td>5.500000</td>\n","      <td>4.200000</td>\n","      <td>3.500000</td>\n","      <td>4.000000</td>\n","      <td>6.333333</td>\n","      <td>4.333333</td>\n","      <td>2.833333</td>\n","      <td>4</td>\n","      <td>0.683333</td>\n","      <td>0.733333</td>\n","      <td>0.883333</td>\n","      <td>0.583333</td>\n","      <td>0.416667</td>\n","      <td>24</td>\n","      <td>26</td>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>15</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>0.38</td>\n","      <td>-1.59</td>\n","      <td>4.64</td>\n","      <td>0.78</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>298</td>\n","      <td>0.074762</td>\n","      <td>11.461538</td>\n","      <td>0.249949</td>\n","      <td>162.167200</td>\n","      <td>0.578592</td>\n","      <td>1529.54</td>\n","      <td>0.400177</td>\n","      <td>26</td>\n","      <td>0.059908</td>\n","      <td>15.384615</td>\n","      <td>0.567781</td>\n","      <td>125</td>\n","      <td>0.400641</td>\n","      <td>764</td>\n","      <td>0.062469</td>\n","      <td>29.384615</td>\n","      <td>0.215993</td>\n","      <td>167</td>\n","      <td>0.169543</td>\n","      <td>0.782264</td>\n","      <td>0.203949</td>\n","      <td>0.012210</td>\n","      <td>0.001577</td>\n","      <td>0.300151</td>\n","      <td>0.233183</td>\n","      <td>0.230322</td>\n","      <td>0.236344</td>\n","      <td>8</td>\n","      <td>55</td>\n","      <td>-0.71</td>\n","      <td>3.302.708.333</td>\n","      <td>3.037.500.024</td>\n","      <td>1.476.083.333</td>\n","      <td>2.912.499.994</td>\n","      <td>0.746794</td>\n","      <td>0.579783</td>\n","      <td>988.272.047</td>\n","      <td>0</td>\n","      <td>0.959899291</td>\n","      <td>0.959899291</td>\n","      <td>0</td>\n","      <td>4</td>\n","      <td>0.529475</td>\n","      <td>0.029491</td>\n","      <td>0.125285</td>\n","      <td>0.000506</td>\n","      <td>0.844718</td>\n","      <td>0.121923</td>\n","      <td>0.685490</td>\n","      <td>0.083875</td>\n","      <td>0.108711</td>\n","      <td>0.535406</td>\n","      <td>0.037475</td>\n","      <td>0.427119</td>\n","      <td>4.666667</td>\n","      <td>3.666667</td>\n","      <td>4.333333</td>\n","      <td>4.500000</td>\n","      <td>4.666667</td>\n","      <td>4.366667</td>\n","      <td>3.666667</td>\n","      <td>4.833333</td>\n","      <td>6.000000</td>\n","      <td>5.333333</td>\n","      <td>4.333333</td>\n","      <td>5</td>\n","      <td>0.533333</td>\n","      <td>0.683333</td>\n","      <td>0.716667</td>\n","      <td>0.500000</td>\n","      <td>0.516667</td>\n","      <td>28</td>\n","      <td>20</td>\n","      <td>21</td>\n","      <td>23</td>\n","      <td>24</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>8</td>\n","      <td>1.77</td>\n","      <td>-1.18</td>\n","      <td>3.61</td>\n","      <td>0.78</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>697</td>\n","      <td>0.174862</td>\n","      <td>8.822785</td>\n","      <td>0.192404</td>\n","      <td>47.935696</td>\n","      <td>0.171028</td>\n","      <td>1421.86</td>\n","      <td>0.372004</td>\n","      <td>79</td>\n","      <td>0.182028</td>\n","      <td>4.455696</td>\n","      <td>0.164441</td>\n","      <td>108</td>\n","      <td>0.346154</td>\n","      <td>2062</td>\n","      <td>0.168602</td>\n","      <td>26.101266</td>\n","      <td>0.191859</td>\n","      <td>257</td>\n","      <td>0.260914</td>\n","      <td>0.735439</td>\n","      <td>0.228609</td>\n","      <td>0.030550</td>\n","      <td>0.005402</td>\n","      <td>0.295444</td>\n","      <td>0.239446</td>\n","      <td>0.225465</td>\n","      <td>0.239646</td>\n","      <td>8</td>\n","      <td>55</td>\n","      <td>-0.71</td>\n","      <td>2.095.583.333</td>\n","      <td>3.866.666.635</td>\n","      <td>1.623.819.444</td>\n","      <td>2.291.666.687</td>\n","      <td>0.428550</td>\n","      <td>0.236425</td>\n","      <td>9.147.384.644</td>\n","      <td>0.061817313</td>\n","      <td>0.254338987</td>\n","      <td>0.127169494</td>\n","      <td>0.061817313</td>\n","      <td>1</td>\n","      <td>0.518237</td>\n","      <td>0.249223</td>\n","      <td>0.057101</td>\n","      <td>0.193481</td>\n","      <td>0.500194</td>\n","      <td>0.070225</td>\n","      <td>0.553516</td>\n","      <td>0.309070</td>\n","      <td>0.067189</td>\n","      <td>0.065323</td>\n","      <td>0.311680</td>\n","      <td>0.622997</td>\n","      <td>3.000000</td>\n","      <td>2.666667</td>\n","      <td>3.166667</td>\n","      <td>5.000000</td>\n","      <td>5.000000</td>\n","      <td>3.766667</td>\n","      <td>3.666667</td>\n","      <td>5.833333</td>\n","      <td>4.333333</td>\n","      <td>3.000000</td>\n","      <td>2.833333</td>\n","      <td>4</td>\n","      <td>0.616667</td>\n","      <td>0.700000</td>\n","      <td>0.716667</td>\n","      <td>0.716667</td>\n","      <td>0.550000</td>\n","      <td>17</td>\n","      <td>23</td>\n","      <td>16</td>\n","      <td>13</td>\n","      <td>14</td>\n","      <td>2</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>4</td>\n","      <td>1.72</td>\n","      <td>-2.00</td>\n","      <td>4.37</td>\n","      <td>0.77</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>276</td>\n","      <td>0.069242</td>\n","      <td>6.272727</td>\n","      <td>0.136793</td>\n","      <td>25.912727</td>\n","      <td>0.092453</td>\n","      <td>218.84</td>\n","      <td>0.057256</td>\n","      <td>44</td>\n","      <td>0.101382</td>\n","      <td>3.113636</td>\n","      <td>0.114911</td>\n","      <td>24</td>\n","      <td>0.076923</td>\n","      <td>857</td>\n","      <td>0.070074</td>\n","      <td>19.477273</td>\n","      <td>0.143169</td>\n","      <td>78</td>\n","      <td>0.079188</td>\n","      <td>0.710042</td>\n","      <td>0.214038</td>\n","      <td>0.066733</td>\n","      <td>0.009187</td>\n","      <td>0.298211</td>\n","      <td>0.236990</td>\n","      <td>0.226584</td>\n","      <td>0.238215</td>\n","      <td>24</td>\n","      <td>71</td>\n","      <td>-0.32</td>\n","      <td>1.213.291.667</td>\n","      <td>1.720.833.361</td>\n","      <td>9.400.256.481</td>\n","      <td>287.179.486</td>\n","      <td>0.259263</td>\n","      <td>0.253813</td>\n","      <td>9.067.036.629</td>\n","      <td>0.03761133</td>\n","      <td>0.098445511</td>\n","      <td>0.098445511</td>\n","      <td>0.03761133</td>\n","      <td>3</td>\n","      <td>0.497027</td>\n","      <td>0.193271</td>\n","      <td>0.038510</td>\n","      <td>0.087476</td>\n","      <td>0.680743</td>\n","      <td>0.150721</td>\n","      <td>0.602558</td>\n","      <td>0.153305</td>\n","      <td>0.093417</td>\n","      <td>0.221334</td>\n","      <td>0.277272</td>\n","      <td>0.501394</td>\n","      <td>1.500000</td>\n","      <td>2.000000</td>\n","      <td>1.333333</td>\n","      <td>3.166667</td>\n","      <td>5.000000</td>\n","      <td>2.600000</td>\n","      <td>5.333333</td>\n","      <td>4.500000</td>\n","      <td>6.166667</td>\n","      <td>5.500000</td>\n","      <td>3.166667</td>\n","      <td>5</td>\n","      <td>0.533333</td>\n","      <td>0.700000</td>\n","      <td>0.583333</td>\n","      <td>0.550000</td>\n","      <td>0.583333</td>\n","      <td>27</td>\n","      <td>26</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>0.90</td>\n","      <td>-0.13</td>\n","      <td>5.33</td>\n","      <td>0.90</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>266</td>\n","      <td>0.166562</td>\n","      <td>9.851852</td>\n","      <td>0.207658</td>\n","      <td>95.963077</td>\n","      <td>0.123819</td>\n","      <td>1446.52</td>\n","      <td>0.226016</td>\n","      <td>27</td>\n","      <td>0.174194</td>\n","      <td>4.740741</td>\n","      <td>0.115024</td>\n","      <td>40</td>\n","      <td>0.242424</td>\n","      <td>543</td>\n","      <td>0.164945</td>\n","      <td>20.111111</td>\n","      <td>0.200261</td>\n","      <td>83</td>\n","      <td>0.166000</td>\n","      <td>0.850650</td>\n","      <td>0.140287</td>\n","      <td>0.007156</td>\n","      <td>0.001907</td>\n","      <td>0.268266</td>\n","      <td>0.257794</td>\n","      <td>0.243564</td>\n","      <td>0.230376</td>\n","      <td>9</td>\n","      <td>60</td>\n","      <td>-0.70</td>\n","      <td>4.099.444.444</td>\n","      <td>2.966.666.698</td>\n","      <td>1.503.222.222</td>\n","      <td>200.999.999</td>\n","      <td>0.417330</td>\n","      <td>0.146854</td>\n","      <td>867.734.657</td>\n","      <td>0.900596442</td>\n","      <td>0.174141428</td>\n","      <td>0.080865228</td>\n","      <td>224.194.098</td>\n","      <td>4</td>\n","      <td>0.547170</td>\n","      <td>0.443086</td>\n","      <td>0.000356</td>\n","      <td>0.333701</td>\n","      <td>0.222857</td>\n","      <td>0.290449</td>\n","      <td>0.443599</td>\n","      <td>0.177075</td>\n","      <td>0.088877</td>\n","      <td>0.399318</td>\n","      <td>0.391894</td>\n","      <td>0.208788</td>\n","      <td>1.666667</td>\n","      <td>5.666667</td>\n","      <td>3.166667</td>\n","      <td>6.500000</td>\n","      <td>5.000000</td>\n","      <td>4.400000</td>\n","      <td>6.666667</td>\n","      <td>4.166667</td>\n","      <td>6.000000</td>\n","      <td>4.666667</td>\n","      <td>4.000000</td>\n","      <td>5</td>\n","      <td>0.583333</td>\n","      <td>0.733333</td>\n","      <td>0.616667</td>\n","      <td>0.650000</td>\n","      <td>0.383333</td>\n","      <td>23</td>\n","      <td>23</td>\n","      <td>20</td>\n","      <td>23</td>\n","      <td>18</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>5</td>\n","      <td>7</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>6</td>\n","      <td>2</td>\n","      <td>6</td>\n","      <td>6</td>\n","      <td>0.17</td>\n","      <td>-1.66</td>\n","      <td>5.57</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>206</td>\n","      <td>0.128992</td>\n","      <td>5.567568</td>\n","      <td>0.117353</td>\n","      <td>67.669189</td>\n","      <td>0.087312</td>\n","      <td>1046.36</td>\n","      <td>0.163492</td>\n","      <td>37</td>\n","      <td>0.238710</td>\n","      <td>3.054054</td>\n","      <td>0.074100</td>\n","      <td>11</td>\n","      <td>0.066667</td>\n","      <td>547</td>\n","      <td>0.166160</td>\n","      <td>14.783784</td>\n","      <td>0.147213</td>\n","      <td>38</td>\n","      <td>0.076000</td>\n","      <td>0.859285</td>\n","      <td>0.132217</td>\n","      <td>0.008067</td>\n","      <td>0.000432</td>\n","      <td>0.258766</td>\n","      <td>0.265813</td>\n","      <td>0.243549</td>\n","      <td>0.231872</td>\n","      <td>14</td>\n","      <td>65</td>\n","      <td>-0.57</td>\n","      <td>2.239.142.833</td>\n","      <td>1.705.714.297</td>\n","      <td>2.081.333.333</td>\n","      <td>2.793.333.387</td>\n","      <td>0.374595</td>\n","      <td>0.214163</td>\n","      <td>994.641.037</td>\n","      <td>0.159374716</td>\n","      <td>1.422.213.784</td>\n","      <td>0.673765582</td>\n","      <td>0.441292182</td>\n","      <td>5</td>\n","      <td>0.532976</td>\n","      <td>0.083002</td>\n","      <td>0.016628</td>\n","      <td>0.144063</td>\n","      <td>0.756307</td>\n","      <td>0.152018</td>\n","      <td>0.409034</td>\n","      <td>0.171133</td>\n","      <td>0.267815</td>\n","      <td>0.299807</td>\n","      <td>0.324159</td>\n","      <td>0.376034</td>\n","      <td>1.500000</td>\n","      <td>1.333333</td>\n","      <td>2.666667</td>\n","      <td>1.333333</td>\n","      <td>5.333333</td>\n","      <td>2.433333</td>\n","      <td>3.666667</td>\n","      <td>3.833333</td>\n","      <td>6.000000</td>\n","      <td>5.666667</td>\n","      <td>2.833333</td>\n","      <td>4</td>\n","      <td>0.566667</td>\n","      <td>0.716667</td>\n","      <td>0.583333</td>\n","      <td>0.616667</td>\n","      <td>0.583333</td>\n","      <td>20</td>\n","      <td>25</td>\n","      <td>15</td>\n","      <td>13</td>\n","      <td>12</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>3</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>5</td>\n","      <td>6</td>\n","      <td>1.41</td>\n","      <td>-1.19</td>\n","      <td>5.05</td>\n","      <td>0.93</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>21</td>\n","      <td>0.013150</td>\n","      <td>3.000000</td>\n","      <td>0.063234</td>\n","      <td>385.191429</td>\n","      <td>0.497002</td>\n","      <td>1465.98</td>\n","      <td>0.229057</td>\n","      <td>7</td>\n","      <td>0.045161</td>\n","      <td>20.285714</td>\n","      <td>0.492190</td>\n","      <td>50</td>\n","      <td>0.303030</td>\n","      <td>53</td>\n","      <td>0.016100</td>\n","      <td>7.571429</td>\n","      <td>0.075394</td>\n","      <td>16</td>\n","      <td>0.032000</td>\n","      <td>0.842470</td>\n","      <td>0.148914</td>\n","      <td>0.008367</td>\n","      <td>0.000250</td>\n","      <td>0.260389</td>\n","      <td>0.269587</td>\n","      <td>0.246609</td>\n","      <td>0.223415</td>\n","      <td>5</td>\n","      <td>56</td>\n","      <td>-0.82</td>\n","      <td>1.414.444.444</td>\n","      <td>1.316.666.675</td>\n","      <td>0.266666667</td>\n","      <td>1.533.333.325</td>\n","      <td>0.397734</td>\n","      <td>0.225812</td>\n","      <td>1.037.045.288</td>\n","      <td>0.057181978</td>\n","      <td>0.35519399</td>\n","      <td>0.237660702</td>\n","      <td>0.057181978</td>\n","      <td>4</td>\n","      <td>0.540482</td>\n","      <td>0.398627</td>\n","      <td>0.000415</td>\n","      <td>0.000592</td>\n","      <td>0.600366</td>\n","      <td>0.033830</td>\n","      <td>0.774783</td>\n","      <td>0.176173</td>\n","      <td>0.015214</td>\n","      <td>0.004723</td>\n","      <td>0.383587</td>\n","      <td>0.611690</td>\n","      <td>3.500000</td>\n","      <td>4.333333</td>\n","      <td>3.166667</td>\n","      <td>3.166667</td>\n","      <td>4.666667</td>\n","      <td>3.766667</td>\n","      <td>3.833333</td>\n","      <td>3.000000</td>\n","      <td>3.833333</td>\n","      <td>3.500000</td>\n","      <td>2.333333</td>\n","      <td>3</td>\n","      <td>0.600000</td>\n","      <td>0.666667</td>\n","      <td>0.633333</td>\n","      <td>0.650000</td>\n","      <td>0.466667</td>\n","      <td>25</td>\n","      <td>21</td>\n","      <td>17</td>\n","      <td>15</td>\n","      <td>18</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>7</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>2.20</td>\n","      <td>-2.16</td>\n","      <td>4.60</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4a567e6d-881b-4776-b0f7-7cc1aa895057')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-4a567e6d-881b-4776-b0f7-7cc1aa895057 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-4a567e6d-881b-4776-b0f7-7cc1aa895057');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":6}]},{"cell_type":"code","source":["df.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OJhwr4rwOSbg","executionInfo":{"status":"ok","timestamp":1685209809493,"user_tz":-120,"elapsed":23,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"8a4fd5d2-e8b8-4f0f-d2df-434eb3b3bf9f"},"id":"OJhwr4rwOSbg","execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(57, 94)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["# Strip off leading and trailing whitespace from non-numeric columns\n","df = df.select_dtypes(include=['int', 'float'])\n","df.reset_index(drop=True, inplace=True)"],"metadata":{"id":"oamWBOvoMZXl","executionInfo":{"status":"ok","timestamp":1685209809494,"user_tz":-120,"elapsed":21,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"oamWBOvoMZXl","execution_count":8,"outputs":[]},{"cell_type":"code","source":["def create_random_df(df):\n","  limit0= 0\n","  limit1= 28 #28 Column: messages_sent\n","  limit2= 45 #45 Column: Groupflow_Antflow\n","  limit3= 81 #Index: 81 Column: transcendence\n","\n","  # Generate two random integers within the range 1-8\n","  range_1 = random.sample(range(limit0, limit1), 2)\n","\n","  # Generate two random integers within the range 9-16\n","  range_2 = random.sample(range(limit1, limit2), 2)\n","\n","  # Generate two random integers within the range 17-25\n","  range_3 = random.sample(range(limit2, limit3), 2)\n","\n","  # Combine all six integers into a single list\n","  column_indexes = range_1 + range_2 + range_3\n","\n","  new_df = df.iloc[:, column_indexes].copy()\n","  data = pd.concat([new_df, df['theory']], axis=1)\n","  data = min_max_scaling_df(data)\n","  selected_columns = df.columns[column_indexes].to_list()\n","\n","  return data,selected_columns"],"metadata":{"id":"pqfsEij82DGm","executionInfo":{"status":"ok","timestamp":1685209809495,"user_tz":-120,"elapsed":22,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"pqfsEij82DGm","execution_count":9,"outputs":[]},{"cell_type":"code","source":["def create_random_df_by_columns(df,column_names):\n","\n","  new_df = df[column_names].copy()\n","  data = pd.concat([new_df, df['theory']], axis=1)\n","  data = min_max_scaling_df(data)\n","\n","  return data"],"metadata":{"id":"_2XCrNoKR5RK","executionInfo":{"status":"ok","timestamp":1685209809496,"user_tz":-120,"elapsed":22,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"_2XCrNoKR5RK","execution_count":10,"outputs":[]},{"cell_type":"code","source":["#df= drop_bad_measured(df)\n"],"metadata":{"id":"0iPmh6s9eOOM","executionInfo":{"status":"ok","timestamp":1685209809497,"user_tz":-120,"elapsed":23,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"0iPmh6s9eOOM","execution_count":11,"outputs":[]},{"cell_type":"markdown","source":["## Regression Models"],"metadata":{"id":"9TPcXVKwp16d"},"id":"9TPcXVKwp16d"},{"cell_type":"code","source":["def grid_search_cv(df):\n","  from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n","  from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n","  from sklearn.linear_model import LinearRegression\n","  from sklearn.tree import DecisionTreeRegressor\n","  from sklearn.ensemble import RandomForestRegressor\n","\n","  # Split the data into training and test sets\n","  X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.2, random_state=42)\n","\n","  # Define the list of models to evaluate\n","  models = [\n","      ('Linear Regression', LinearRegression()),\n","      ('Decision Tree', DecisionTreeRegressor()),\n","      ('Random Forest', RandomForestRegressor())\n","  ]\n","\n","  # Define the grid of hyperparameters for each model\n","  param_grid = {\n","      'Linear Regression': {},\n","      'Decision Tree': {'max_depth': [None, 5, 10]},\n","      'Random Forest': {'n_estimators': [100, 200, 300]}\n","  }\n","\n","  # Define the scoring metrics for evaluation\n","  scoring = {\n","      'RMSE': make_scorer(mean_squared_error, squared=False),\n","      'R2': make_scorer(r2_score)\n","  }\n","\n","  # Perform grid search and cross-validation for each model\n","  results = {}\n","  for name, model in models:\n","      grid_search = GridSearchCV(model, param_grid[name], scoring=scoring, refit='RMSE', cv=5)\n","      grid_search.fit(X_train, y_train)\n","      \n","      # Cross-validation scores for all parameter combinations\n","      cv_results = cross_validate(grid_search.best_estimator_, X_train, y_train, scoring=scoring, cv=5)\n","      \n","      results[name] = {\n","          'best_params': grid_search.best_params_,\n","          'best_estimator': grid_search.best_estimator_,\n","          'cv_RMSE': cv_results['test_RMSE'].mean(),\n","          'cv_R2': cv_results['test_R2'].mean()\n","      }\n","\n","  # Print the results for all models and parameter combinations\n","  for name, result in results.items():\n","      print(\"Model:\", name)\n","      print(\"Best Parameters:\", result['best_params'])\n","      print(\"CV RMSE:\", result['cv_RMSE'])\n","      print(\"CV R2:\", result['cv_R2'])\n","      print()\n","\n","  # Train the best model on the entire training dataset\n","  best_model = min(results, key=lambda x: results[x]['cv_RMSE'])\n","  final_model = results[best_model]['best_estimator']\n","  final_model.fit(X_train, y_train)\n","\n","  # Evaluate the performance of the best model on the test set\n","  y_pred = final_model.predict(X_test)\n","  mse = mean_squared_error(y_test, y_pred)\n","  rmse = np.sqrt(mse)\n","  r2 = r2_score(y_test, y_pred)\n","  print(\"Best Model:\", best_model)\n","  print(\"Test RMSE:\", rmse)\n","  print(\"Test R2:\", r2)\n"],"metadata":{"id":"TpBGFm5EikkM","executionInfo":{"status":"ok","timestamp":1685209809499,"user_tz":-120,"elapsed":24,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"TpBGFm5EikkM","execution_count":12,"outputs":[]},{"cell_type":"code","source":["def try_regressions(df):\n","\n","  # Step 2: Split the data into features (X) and the objective variable (y)\n","  X = df.iloc[:, :-1]  # All columns except the last one\n","  y = df.iloc[:, -1]   # Last column\n","\n","  # Step 3: Split the data into training and testing sets\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","  # Step 4: Build and evaluate different OLS models\n","  models = []\n","\n","  # Model 1: OLS using statsmodels\n","  model1 = sm.OLS(y_train, sm.add_constant(X_train))\n","  results1 = model1.fit()\n","  models.append(results1)\n","\n","  # Model 2: OLS using scikit-learn (linear regression)\n","  from sklearn.linear_model import LinearRegression\n","  model2 = LinearRegression()\n","  model2.fit(X_train, y_train)\n","  models.append(model2)\n","\n","  # Model 3: OLS using scikit-learn (Ridge regression)\n","  from sklearn.linear_model import Ridge\n","  model3 = Ridge(alpha=1.0)  # You can adjust the regularization parameter (alpha) as needed\n","  model3.fit(X_train, y_train)\n","  models.append(model3)\n","\n","  # Step 5: Evaluate the models on the testing set\n","  for model in models:\n","      if isinstance(model, sm.regression.linear_model.RegressionResultsWrapper):\n","          X_test_with_constant = sm.add_constant(X_test)\n","          y_pred = model.predict(X_test_with_constant)\n","          r2 = model.rsquared\n","      else:\n","          y_pred = model.predict(X_test)\n","          r2 = model.score(X_test, y_test)\n","\n","      # Calculate evaluation metrics (e.g., mean squared error)\n","      mse = np.mean((y_pred - y_test) ** 2)\n","\n","      # Print the evaluation results\n","      print(model)\n","      print(\"Mean Squared Error:\", mse)\n","      print(\"R-squared:\", r2)\n","      print()\n","\n"],"metadata":{"id":"qyWMTe9d7kdQ","executionInfo":{"status":"ok","timestamp":1685209809503,"user_tz":-120,"elapsed":27,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"qyWMTe9d7kdQ","execution_count":15,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.linear_model import LinearRegression, Ridge\n","\n","def try_regressions(df):\n","    # Step 2: Split the data into features (X) and the objective variable (y)\n","    X = df.iloc[:, :-1]  # All columns except the last one\n","    y = df.iloc[:, -1]   # Last column\n","\n","    # Step 3: Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Step 4: Build and evaluate different OLS models\n","    models = []\n","\n","    # Model 1: OLS using scikit-learn (linear regression)\n","    model1 = LinearRegression()\n","    model1.fit(X_train, y_train)\n","    models.append(('Linear Regression', model1))\n","\n","    # Model 2: OLS using scikit-learn (Ridge regression)\n","    model2 = Ridge(alpha=1.0)  # You can adjust the regularization parameter (alpha) as needed\n","    model2.fit(X_train, y_train)\n","    models.append(('Ridge Regression', model2))\n","\n","    # Step 5: Evaluate the models using cross-validation\n","    for name, model in models:\n","        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n","        mse = -scores.mean()\n","        r2 = model.score(X_test, y_test)\n","\n","        # Print the evaluation results\n","        print(name)\n","        print(\"Mean Squared Error:\", mse)\n","        print(\"R-squared:\", r2)\n","        print()\n"],"metadata":{"id":"UmucBH-XASzG","executionInfo":{"status":"ok","timestamp":1685209809504,"user_tz":-120,"elapsed":28,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"UmucBH-XASzG","execution_count":16,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.linear_model import LinearRegression, Ridge\n","\n","def try_regressions(df):\n","    # Step 2: Split the data into features (X) and the objective variable (y)\n","    X = df.iloc[:, :-1]  # All columns except the last one\n","    y = df.iloc[:, -1]   # Last column\n","\n","    # Step 3: Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Step 4: Build and evaluate different OLS models\n","    models = []\n","\n","    # Model 1: OLS using scikit-learn (linear regression)\n","    model1 = LinearRegression()\n","    model1.fit(X_train, y_train)\n","    models.append(('Linear Regression', model1))\n","\n","    # Model 2: OLS using scikit-learn (Ridge regression)\n","    model2 = Ridge(alpha=1.0)  # You can adjust the regularization parameter (alpha) as needed\n","    model2.fit(X_train, y_train)\n","    models.append(('Ridge Regression', model2))\n","\n","    # Step 5: Evaluate the models using cross-validation\n","    results = {}\n","\n","    for name, model in models:\n","        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n","        mse = -scores.mean()\n","        r2 = model.score(X_test, y_test)\n","\n","        # Store the evaluation results in a dictionary\n","        results[name] = {'Mean Squared Error': mse, 'R-squared': r2}\n","\n","    return results\n"],"metadata":{"id":"GOMLbr9qDRGN","executionInfo":{"status":"ok","timestamp":1685209809506,"user_tz":-120,"elapsed":29,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"GOMLbr9qDRGN","execution_count":17,"outputs":[]},{"cell_type":"markdown","source":["## Use of Functions"],"metadata":{"id":"d9pT_rns_qjX"},"id":"d9pT_rns_qjX"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","results = []\n","indexes = []\n","\n","for x in range(0, 100000):\n","    df_test, index = create_random_df(df)\n","    results.append(try_regressions(df_test))\n","    indexes.append(index)\n","\n","data = []\n","\n","for i, result in enumerate(results):\n","    for model_name, metrics in result.items():\n","        r2 = metrics['R-squared']\n","        mse = metrics['Mean Squared Error']\n","        data.append([model_name, r2, mse, indexes[i]])\n","\n","df_results = pd.DataFrame(data, columns=['Model', 'R-squared', 'Mean Squared Error', 'Index'])\n","\n","df_results = df_results.sort_values(by='R-squared', ascending=False)\n","\n","df_results.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":363},"id":"Q0VbRxB_Fyi_","executionInfo":{"status":"ok","timestamp":1685215475830,"user_tz":-120,"elapsed":5666353,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"5bc3588c-feb2-4360-9c39-fb60099d4c33"},"id":"Q0VbRxB_Fyi_","execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                    Model  R-squared  Mean Squared Error  \\\n","64754   Linear Regression   0.894838            0.030272   \n","33572   Linear Regression   0.851039            0.055190   \n","99188   Linear Regression   0.839684            0.032252   \n","35126   Linear Regression   0.814960            0.036523   \n","139420  Linear Regression   0.814419            0.024565   \n","36612   Linear Regression   0.813485            0.032413   \n","48252   Linear Regression   0.797601            0.028449   \n","21586   Linear Regression   0.796825            0.029966   \n","71926   Linear Regression   0.791876            0.026885   \n","73528   Linear Regression   0.790335            0.038551   \n","\n","                                                    Index  \n","64754   [max_turns_without_speaking, indiv_spoken_time...  \n","33572   [speech_ang, max_time_without_speaking, contri...  \n","99188   [text_sadness, max_turns_without_speaking, con...  \n","35126   [max_turns_without_speaking, text_joy, contrib...  \n","139420  [avg_words_turn_ratio, avg_turns_without_speak...  \n","36612   [text_sadness, num_words_ratio, Groupflow_Beef...  \n","48252   [text_joy, max_time_without_speaking_ratio, me...  \n","21586   [avg_words_turn, text_joy, ALTERNATIVE_REALITI...  \n","71926   [max_words_turn, average_turn_duration, contri...  \n","73528   [max_time_without_speaking, average_turn_durat...  "],"text/html":["\n","  <div id=\"df-85281e57-cfea-4dd2-847a-b56d567f5395\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>R-squared</th>\n","      <th>Mean Squared Error</th>\n","      <th>Index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>64754</th>\n","      <td>Linear Regression</td>\n","      <td>0.894838</td>\n","      <td>0.030272</td>\n","      <td>[max_turns_without_speaking, indiv_spoken_time...</td>\n","    </tr>\n","    <tr>\n","      <th>33572</th>\n","      <td>Linear Regression</td>\n","      <td>0.851039</td>\n","      <td>0.055190</td>\n","      <td>[speech_ang, max_time_without_speaking, contri...</td>\n","    </tr>\n","    <tr>\n","      <th>99188</th>\n","      <td>Linear Regression</td>\n","      <td>0.839684</td>\n","      <td>0.032252</td>\n","      <td>[text_sadness, max_turns_without_speaking, con...</td>\n","    </tr>\n","    <tr>\n","      <th>35126</th>\n","      <td>Linear Regression</td>\n","      <td>0.814960</td>\n","      <td>0.036523</td>\n","      <td>[max_turns_without_speaking, text_joy, contrib...</td>\n","    </tr>\n","    <tr>\n","      <th>139420</th>\n","      <td>Linear Regression</td>\n","      <td>0.814419</td>\n","      <td>0.024565</td>\n","      <td>[avg_words_turn_ratio, avg_turns_without_speak...</td>\n","    </tr>\n","    <tr>\n","      <th>36612</th>\n","      <td>Linear Regression</td>\n","      <td>0.813485</td>\n","      <td>0.032413</td>\n","      <td>[text_sadness, num_words_ratio, Groupflow_Beef...</td>\n","    </tr>\n","    <tr>\n","      <th>48252</th>\n","      <td>Linear Regression</td>\n","      <td>0.797601</td>\n","      <td>0.028449</td>\n","      <td>[text_joy, max_time_without_speaking_ratio, me...</td>\n","    </tr>\n","    <tr>\n","      <th>21586</th>\n","      <td>Linear Regression</td>\n","      <td>0.796825</td>\n","      <td>0.029966</td>\n","      <td>[avg_words_turn, text_joy, ALTERNATIVE_REALITI...</td>\n","    </tr>\n","    <tr>\n","      <th>71926</th>\n","      <td>Linear Regression</td>\n","      <td>0.791876</td>\n","      <td>0.026885</td>\n","      <td>[max_words_turn, average_turn_duration, contri...</td>\n","    </tr>\n","    <tr>\n","      <th>73528</th>\n","      <td>Linear Regression</td>\n","      <td>0.790335</td>\n","      <td>0.038551</td>\n","      <td>[max_time_without_speaking, average_turn_durat...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-85281e57-cfea-4dd2-847a-b56d567f5395')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-85281e57-cfea-4dd2-847a-b56d567f5395 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-85281e57-cfea-4dd2-847a-b56d567f5395');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["df_results.head(100).to_excel(out_file, index=False)"],"metadata":{"id":"VGf_S5hlPwzN","executionInfo":{"status":"ok","timestamp":1685215477783,"user_tz":-120,"elapsed":1957,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"VGf_S5hlPwzN","execution_count":19,"outputs":[]},{"cell_type":"code","source":["cols= ['text_anger', 'num_turns', 'contribution_index_oscillation', 'messages_sent', 'health_perceived', 'total_likelihood']\n","df_testing= create_random_df_by_columns(df,cols)\n","print(try_regressions(df_testing))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zn4w4N3iSgHH","executionInfo":{"status":"ok","timestamp":1685215477784,"user_tz":-120,"elapsed":32,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"5f64c333-5647-456f-944b-c1d0dac0713b"},"id":"zn4w4N3iSgHH","execution_count":20,"outputs":[{"output_type":"stream","name":"stdout","text":["{'Linear Regression': {'Mean Squared Error': 0.021278770963762923, 'R-squared': 0.7863688588410277}, 'Ridge Regression': {'Mean Squared Error': 0.026921441960571176, 'R-squared': 0.46640281920896276}}\n"]}]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[{"file_id":"1vwdjcqEdBtwdLRVemm2obr9-3EqLFird","timestamp":1683651927472},{"file_id":"1hp8Al1PXfv_qks5p7af_ZlBF-qlMhBFt","timestamp":1683646657357}],"machine_shape":"hm","gpuType":"T4"}},"nbformat":4,"nbformat_minor":5}
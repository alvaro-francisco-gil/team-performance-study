{"cells":[{"cell_type":"markdown","source":["# Group Surveys Feature Determination"],"metadata":{"id":"28sYRJfoFaXt"},"id":"28sYRJfoFaXt"},{"cell_type":"markdown","source":["## Preparation"],"metadata":{"id":"r8p1ntYzFhE0"},"id":"r8p1ntYzFhE0"},{"cell_type":"markdown","source":["### Import"],"metadata":{"id":"1xLE7wUVFjf_"},"id":"1xLE7wUVFjf_"},{"cell_type":"code","execution_count":1,"id":"78992abc","metadata":{"id":"78992abc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1685206493372,"user_tz":-120,"elapsed":6312,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"4feb5b61-576b-4c47-ef41-58fec3dc9782"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n","import random\n","import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import statsmodels.api as sm\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["pd.set_option('display.max_columns', 100)\n","pd.set_option('display.max_rows', 1000)"],"metadata":{"id":"1lCVdGaJ1xG3","executionInfo":{"status":"ok","timestamp":1685206493373,"user_tz":-120,"elapsed":8,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"1lCVdGaJ1xG3","execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["## Function Definition"],"metadata":{"id":"oJryoMlhKyjp"},"id":"oJryoMlhKyjp"},{"cell_type":"markdown","source":["### Min-Max Scaler"],"metadata":{"id":"X0_gNbQdt-Ic"},"id":"X0_gNbQdt-Ic"},{"cell_type":"code","source":["from sklearn.preprocessing import MinMaxScaler\n","\n","def min_max_scaling_df(df):\n","    scaler = MinMaxScaler()\n","    scaled_df = pd.DataFrame(scaler.fit_transform(df), columns=df.columns)\n","    return scaled_df\n"],"metadata":{"id":"FI9xDgQMt9lH","executionInfo":{"status":"ok","timestamp":1685206493373,"user_tz":-120,"elapsed":7,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"FI9xDgQMt9lH","execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Use of Function"],"metadata":{"id":"UZhXb7j6GErP"},"id":"UZhXb7j6GErP"},{"cell_type":"code","source":["in_file= r'/content/drive/MyDrive/Projects/tps/finals/data/4_individual_features.xlsx'\n","out_file= r'/content/drive/MyDrive/Projects/tps/finals/data/5_individual_features.xlsx'"],"metadata":{"id":"IXwECopkgaiJ","executionInfo":{"status":"ok","timestamp":1685206493373,"user_tz":-120,"elapsed":6,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"IXwECopkgaiJ","execution_count":4,"outputs":[]},{"cell_type":"code","source":["df= pd.read_excel(in_file, index_col='Id')\n","df.head(12)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":521},"id":"PsXguzIHvNjp","executionInfo":{"status":"ok","timestamp":1685206495055,"user_tz":-120,"elapsed":1687,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"83bf722f-4266-4487-9664-b4b608d1d473"},"id":"PsXguzIHvNjp","execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    group  indiv_spoken_time_ratio  average_turn_duration  \\\n","Id                                                          \n","1       1                 0.148336               7.850746   \n","2       1                 0.746757              33.948718   \n","3       1                 0.029611               8.076923   \n","4       1                 0.045685               6.480000   \n","5       1                 0.029611               5.526316   \n","6       2                 0.337682               8.518987   \n","8       2                 0.074762              11.461538   \n","9       2                 0.174862               8.822785   \n","10      2                 0.069242               6.272727   \n","11      3                 0.166562               9.851852   \n","12      3                 0.128992               5.567568   \n","13      3                 0.013150               3.000000   \n","\n","    avg_time_without_speaking  num_turns  num_turns_ratio  \\\n","Id                                                          \n","1                   56.210746         67         0.331683   \n","2                   21.791169         78         0.386139   \n","3                   57.649231         13         0.064356   \n","4                  159.421600         25         0.123762   \n","5                   43.632632         19         0.094059   \n","6                   19.887848        158         0.364055   \n","8                  162.167200         26         0.059908   \n","9                   47.935696         79         0.182028   \n","10                  25.912727         44         0.101382   \n","11                  95.963077         27         0.174194   \n","12                  67.669189         37         0.238710   \n","13                 385.191429          7         0.045161   \n","\n","    avg_turns_without_speaking  max_words_turn_ratio  text_joy  messages_sent  \\\n","Id                                                                              \n","1                     1.985075              0.078613  0.298809             34   \n","2                     1.589744              0.720231  0.292950             75   \n","3                     6.461538              0.080925  0.297727             38   \n","4                     6.600000              0.070520  0.300100             27   \n","5                     4.526316              0.049711  0.303593             22   \n","6                     1.740506              0.233503  0.297780             22   \n","8                    15.384615              0.169543  0.300151              8   \n","9                     4.455696              0.260914  0.295444              8   \n","10                    3.113636              0.079188  0.298211             24   \n","11                    4.740741              0.166000  0.268266              9   \n","12                    3.054054              0.076000  0.258766             14   \n","13                   20.285714              0.032000  0.260389              5   \n","\n","    contribution_index  sentiment_avg  emotionality_avg  \\\n","Id                                                        \n","1                -0.64       0.303561          0.215562   \n","2                -0.34       0.250396          0.236507   \n","3                -0.60       0.381860          0.254014   \n","4                -0.70       0.250852          0.259828   \n","5                -0.75       0.305600          0.244289   \n","6                -0.36       0.404612          0.268756   \n","8                -0.71       0.746794          0.579783   \n","9                -0.71       0.428550          0.236425   \n","10               -0.32       0.259263          0.253813   \n","11               -0.70       0.417330          0.146854   \n","12               -0.57       0.374595          0.214163   \n","13               -0.82       0.397734          0.225812   \n","\n","    activity_entanglement  EMOTIONS_Happy  Groupflow_Beeflow  \\\n","Id                                                             \n","1                0.487649        0.407447           0.497477   \n","2                0.398994        0.417419           0.300955   \n","3                0.501416        0.410218           0.226931   \n","4                0.493443        0.322770           0.256794   \n","5                0.555323        0.472688           0.342162   \n","6                0.520000        0.624326           0.332323   \n","8                0.529475        0.685490           0.535406   \n","9                0.518237        0.553516           0.065323   \n","10               0.497027        0.602558           0.221334   \n","11               0.547170        0.443599           0.399318   \n","12               0.532976        0.409034           0.299807   \n","13               0.540482        0.774783           0.004723   \n","\n","    Groupflow_Leechflow         O         C         E         A         N  \\\n","Id                                                                          \n","1              0.156358  0.600000  0.716667  0.600000  0.633333  0.583333   \n","2              0.220056  0.533333  0.666667  0.700000  0.616667  0.633333   \n","3              0.238211  0.566667  0.683333  0.716667  0.533333  0.716667   \n","4              0.232465  0.566667  0.783333  0.733333  0.733333  0.633333   \n","5              0.120088  0.600000  0.666667  0.483333  0.583333  0.433333   \n","6              0.221886  0.683333  0.733333  0.883333  0.583333  0.416667   \n","8              0.037475  0.533333  0.683333  0.716667  0.500000  0.516667   \n","9              0.311680  0.616667  0.700000  0.716667  0.716667  0.550000   \n","10             0.277272  0.533333  0.700000  0.583333  0.550000  0.583333   \n","11             0.391894  0.583333  0.733333  0.616667  0.650000  0.383333   \n","12             0.324159  0.566667  0.716667  0.583333  0.616667  0.583333   \n","13             0.383587  0.600000  0.666667  0.633333  0.650000  0.466667   \n","\n","    harm_care_score  fairness_reciprocity_score  in_group_loyality_score  \\\n","Id                                                                         \n","1                27                          23                       19   \n","2                22                          28                       11   \n","3                23                          28                        9   \n","4                17                          24                       17   \n","5                12                          15                       11   \n","6                24                          26                       13   \n","8                28                          20                       21   \n","9                17                          23                       16   \n","10               27                          26                       18   \n","11               23                          23                       20   \n","12               20                          25                       15   \n","13               25                          21                       17   \n","\n","    authority_respect_score  purity_sanctity_score  theory  coeval  project  \n","Id                                                                           \n","1                        18                     20    3.44    0.90      8.0  \n","2                         7                     11    3.64    0.91      8.0  \n","3                         6                      7    3.98    0.90      8.0  \n","4                        13                      8    4.22    0.90      8.0  \n","5                        19                      4    3.74    0.91      8.0  \n","6                        13                     15    4.64    0.78      8.5  \n","8                        23                     24    3.61    0.78      8.5  \n","9                        13                     14    4.37    0.77      8.5  \n","10                       18                     18    5.33    0.90      8.5  \n","11                       23                     18    5.57    0.91      8.0  \n","12                       13                     12    5.05    0.93      8.0  \n","13                       15                     18    4.60    0.91      8.0  "],"text/html":["\n","  <div id=\"df-a90b52e9-23f9-4f69-a5d7-94f0c0ec6ace\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>group</th>\n","      <th>indiv_spoken_time_ratio</th>\n","      <th>average_turn_duration</th>\n","      <th>avg_time_without_speaking</th>\n","      <th>num_turns</th>\n","      <th>num_turns_ratio</th>\n","      <th>avg_turns_without_speaking</th>\n","      <th>max_words_turn_ratio</th>\n","      <th>text_joy</th>\n","      <th>messages_sent</th>\n","      <th>contribution_index</th>\n","      <th>sentiment_avg</th>\n","      <th>emotionality_avg</th>\n","      <th>activity_entanglement</th>\n","      <th>EMOTIONS_Happy</th>\n","      <th>Groupflow_Beeflow</th>\n","      <th>Groupflow_Leechflow</th>\n","      <th>O</th>\n","      <th>C</th>\n","      <th>E</th>\n","      <th>A</th>\n","      <th>N</th>\n","      <th>harm_care_score</th>\n","      <th>fairness_reciprocity_score</th>\n","      <th>in_group_loyality_score</th>\n","      <th>authority_respect_score</th>\n","      <th>purity_sanctity_score</th>\n","      <th>theory</th>\n","      <th>coeval</th>\n","      <th>project</th>\n","    </tr>\n","    <tr>\n","      <th>Id</th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.148336</td>\n","      <td>7.850746</td>\n","      <td>56.210746</td>\n","      <td>67</td>\n","      <td>0.331683</td>\n","      <td>1.985075</td>\n","      <td>0.078613</td>\n","      <td>0.298809</td>\n","      <td>34</td>\n","      <td>-0.64</td>\n","      <td>0.303561</td>\n","      <td>0.215562</td>\n","      <td>0.487649</td>\n","      <td>0.407447</td>\n","      <td>0.497477</td>\n","      <td>0.156358</td>\n","      <td>0.600000</td>\n","      <td>0.716667</td>\n","      <td>0.600000</td>\n","      <td>0.633333</td>\n","      <td>0.583333</td>\n","      <td>27</td>\n","      <td>23</td>\n","      <td>19</td>\n","      <td>18</td>\n","      <td>20</td>\n","      <td>3.44</td>\n","      <td>0.90</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>0.746757</td>\n","      <td>33.948718</td>\n","      <td>21.791169</td>\n","      <td>78</td>\n","      <td>0.386139</td>\n","      <td>1.589744</td>\n","      <td>0.720231</td>\n","      <td>0.292950</td>\n","      <td>75</td>\n","      <td>-0.34</td>\n","      <td>0.250396</td>\n","      <td>0.236507</td>\n","      <td>0.398994</td>\n","      <td>0.417419</td>\n","      <td>0.300955</td>\n","      <td>0.220056</td>\n","      <td>0.533333</td>\n","      <td>0.666667</td>\n","      <td>0.700000</td>\n","      <td>0.616667</td>\n","      <td>0.633333</td>\n","      <td>22</td>\n","      <td>28</td>\n","      <td>11</td>\n","      <td>7</td>\n","      <td>11</td>\n","      <td>3.64</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>0.029611</td>\n","      <td>8.076923</td>\n","      <td>57.649231</td>\n","      <td>13</td>\n","      <td>0.064356</td>\n","      <td>6.461538</td>\n","      <td>0.080925</td>\n","      <td>0.297727</td>\n","      <td>38</td>\n","      <td>-0.60</td>\n","      <td>0.381860</td>\n","      <td>0.254014</td>\n","      <td>0.501416</td>\n","      <td>0.410218</td>\n","      <td>0.226931</td>\n","      <td>0.238211</td>\n","      <td>0.566667</td>\n","      <td>0.683333</td>\n","      <td>0.716667</td>\n","      <td>0.533333</td>\n","      <td>0.716667</td>\n","      <td>23</td>\n","      <td>28</td>\n","      <td>9</td>\n","      <td>6</td>\n","      <td>7</td>\n","      <td>3.98</td>\n","      <td>0.90</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>1</td>\n","      <td>0.045685</td>\n","      <td>6.480000</td>\n","      <td>159.421600</td>\n","      <td>25</td>\n","      <td>0.123762</td>\n","      <td>6.600000</td>\n","      <td>0.070520</td>\n","      <td>0.300100</td>\n","      <td>27</td>\n","      <td>-0.70</td>\n","      <td>0.250852</td>\n","      <td>0.259828</td>\n","      <td>0.493443</td>\n","      <td>0.322770</td>\n","      <td>0.256794</td>\n","      <td>0.232465</td>\n","      <td>0.566667</td>\n","      <td>0.783333</td>\n","      <td>0.733333</td>\n","      <td>0.733333</td>\n","      <td>0.633333</td>\n","      <td>17</td>\n","      <td>24</td>\n","      <td>17</td>\n","      <td>13</td>\n","      <td>8</td>\n","      <td>4.22</td>\n","      <td>0.90</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>1</td>\n","      <td>0.029611</td>\n","      <td>5.526316</td>\n","      <td>43.632632</td>\n","      <td>19</td>\n","      <td>0.094059</td>\n","      <td>4.526316</td>\n","      <td>0.049711</td>\n","      <td>0.303593</td>\n","      <td>22</td>\n","      <td>-0.75</td>\n","      <td>0.305600</td>\n","      <td>0.244289</td>\n","      <td>0.555323</td>\n","      <td>0.472688</td>\n","      <td>0.342162</td>\n","      <td>0.120088</td>\n","      <td>0.600000</td>\n","      <td>0.666667</td>\n","      <td>0.483333</td>\n","      <td>0.583333</td>\n","      <td>0.433333</td>\n","      <td>12</td>\n","      <td>15</td>\n","      <td>11</td>\n","      <td>19</td>\n","      <td>4</td>\n","      <td>3.74</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>2</td>\n","      <td>0.337682</td>\n","      <td>8.518987</td>\n","      <td>19.887848</td>\n","      <td>158</td>\n","      <td>0.364055</td>\n","      <td>1.740506</td>\n","      <td>0.233503</td>\n","      <td>0.297780</td>\n","      <td>22</td>\n","      <td>-0.36</td>\n","      <td>0.404612</td>\n","      <td>0.268756</td>\n","      <td>0.520000</td>\n","      <td>0.624326</td>\n","      <td>0.332323</td>\n","      <td>0.221886</td>\n","      <td>0.683333</td>\n","      <td>0.733333</td>\n","      <td>0.883333</td>\n","      <td>0.583333</td>\n","      <td>0.416667</td>\n","      <td>24</td>\n","      <td>26</td>\n","      <td>13</td>\n","      <td>13</td>\n","      <td>15</td>\n","      <td>4.64</td>\n","      <td>0.78</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>0.074762</td>\n","      <td>11.461538</td>\n","      <td>162.167200</td>\n","      <td>26</td>\n","      <td>0.059908</td>\n","      <td>15.384615</td>\n","      <td>0.169543</td>\n","      <td>0.300151</td>\n","      <td>8</td>\n","      <td>-0.71</td>\n","      <td>0.746794</td>\n","      <td>0.579783</td>\n","      <td>0.529475</td>\n","      <td>0.685490</td>\n","      <td>0.535406</td>\n","      <td>0.037475</td>\n","      <td>0.533333</td>\n","      <td>0.683333</td>\n","      <td>0.716667</td>\n","      <td>0.500000</td>\n","      <td>0.516667</td>\n","      <td>28</td>\n","      <td>20</td>\n","      <td>21</td>\n","      <td>23</td>\n","      <td>24</td>\n","      <td>3.61</td>\n","      <td>0.78</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>2</td>\n","      <td>0.174862</td>\n","      <td>8.822785</td>\n","      <td>47.935696</td>\n","      <td>79</td>\n","      <td>0.182028</td>\n","      <td>4.455696</td>\n","      <td>0.260914</td>\n","      <td>0.295444</td>\n","      <td>8</td>\n","      <td>-0.71</td>\n","      <td>0.428550</td>\n","      <td>0.236425</td>\n","      <td>0.518237</td>\n","      <td>0.553516</td>\n","      <td>0.065323</td>\n","      <td>0.311680</td>\n","      <td>0.616667</td>\n","      <td>0.700000</td>\n","      <td>0.716667</td>\n","      <td>0.716667</td>\n","      <td>0.550000</td>\n","      <td>17</td>\n","      <td>23</td>\n","      <td>16</td>\n","      <td>13</td>\n","      <td>14</td>\n","      <td>4.37</td>\n","      <td>0.77</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>2</td>\n","      <td>0.069242</td>\n","      <td>6.272727</td>\n","      <td>25.912727</td>\n","      <td>44</td>\n","      <td>0.101382</td>\n","      <td>3.113636</td>\n","      <td>0.079188</td>\n","      <td>0.298211</td>\n","      <td>24</td>\n","      <td>-0.32</td>\n","      <td>0.259263</td>\n","      <td>0.253813</td>\n","      <td>0.497027</td>\n","      <td>0.602558</td>\n","      <td>0.221334</td>\n","      <td>0.277272</td>\n","      <td>0.533333</td>\n","      <td>0.700000</td>\n","      <td>0.583333</td>\n","      <td>0.550000</td>\n","      <td>0.583333</td>\n","      <td>27</td>\n","      <td>26</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>18</td>\n","      <td>5.33</td>\n","      <td>0.90</td>\n","      <td>8.5</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>3</td>\n","      <td>0.166562</td>\n","      <td>9.851852</td>\n","      <td>95.963077</td>\n","      <td>27</td>\n","      <td>0.174194</td>\n","      <td>4.740741</td>\n","      <td>0.166000</td>\n","      <td>0.268266</td>\n","      <td>9</td>\n","      <td>-0.70</td>\n","      <td>0.417330</td>\n","      <td>0.146854</td>\n","      <td>0.547170</td>\n","      <td>0.443599</td>\n","      <td>0.399318</td>\n","      <td>0.391894</td>\n","      <td>0.583333</td>\n","      <td>0.733333</td>\n","      <td>0.616667</td>\n","      <td>0.650000</td>\n","      <td>0.383333</td>\n","      <td>23</td>\n","      <td>23</td>\n","      <td>20</td>\n","      <td>23</td>\n","      <td>18</td>\n","      <td>5.57</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>3</td>\n","      <td>0.128992</td>\n","      <td>5.567568</td>\n","      <td>67.669189</td>\n","      <td>37</td>\n","      <td>0.238710</td>\n","      <td>3.054054</td>\n","      <td>0.076000</td>\n","      <td>0.258766</td>\n","      <td>14</td>\n","      <td>-0.57</td>\n","      <td>0.374595</td>\n","      <td>0.214163</td>\n","      <td>0.532976</td>\n","      <td>0.409034</td>\n","      <td>0.299807</td>\n","      <td>0.324159</td>\n","      <td>0.566667</td>\n","      <td>0.716667</td>\n","      <td>0.583333</td>\n","      <td>0.616667</td>\n","      <td>0.583333</td>\n","      <td>20</td>\n","      <td>25</td>\n","      <td>15</td>\n","      <td>13</td>\n","      <td>12</td>\n","      <td>5.05</td>\n","      <td>0.93</td>\n","      <td>8.0</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>3</td>\n","      <td>0.013150</td>\n","      <td>3.000000</td>\n","      <td>385.191429</td>\n","      <td>7</td>\n","      <td>0.045161</td>\n","      <td>20.285714</td>\n","      <td>0.032000</td>\n","      <td>0.260389</td>\n","      <td>5</td>\n","      <td>-0.82</td>\n","      <td>0.397734</td>\n","      <td>0.225812</td>\n","      <td>0.540482</td>\n","      <td>0.774783</td>\n","      <td>0.004723</td>\n","      <td>0.383587</td>\n","      <td>0.600000</td>\n","      <td>0.666667</td>\n","      <td>0.633333</td>\n","      <td>0.650000</td>\n","      <td>0.466667</td>\n","      <td>25</td>\n","      <td>21</td>\n","      <td>17</td>\n","      <td>15</td>\n","      <td>18</td>\n","      <td>4.60</td>\n","      <td>0.91</td>\n","      <td>8.0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a90b52e9-23f9-4f69-a5d7-94f0c0ec6ace')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-a90b52e9-23f9-4f69-a5d7-94f0c0ec6ace button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-a90b52e9-23f9-4f69-a5d7-94f0c0ec6ace');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["def create_random_df(df):\n","  limit0= 1\n","  limit1= 9\n","  limit2= 17\n","  limit3= 26\n","\n","  # Generate two random integers within the range 1-8\n","  range_1 = random.sample(range(limit0, limit1), 2)\n","\n","  # Generate two random integers within the range 9-16\n","  range_2 = random.sample(range(limit1, limit2), 2)\n","\n","  # Generate two random integers within the range 17-25\n","  range_3 = random.sample(range(limit2, limit3), 2)\n","\n","  # Combine all six integers into a single list\n","  column_indexes = range_1 + range_2 + range_3\n","\n","  new_df = df.iloc[:, column_indexes].copy()\n","  data = pd.concat([new_df, df['theory']], axis=1)\n","  data = min_max_scaling_df(data)\n","  selected_columns = df.columns[column_indexes].to_list()\n","\n","  return data,selected_columns"],"metadata":{"id":"pqfsEij82DGm","executionInfo":{"status":"ok","timestamp":1685206495056,"user_tz":-120,"elapsed":22,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"pqfsEij82DGm","execution_count":6,"outputs":[]},{"cell_type":"code","source":["#df= drop_bad_measured(df)\n"],"metadata":{"id":"0iPmh6s9eOOM","executionInfo":{"status":"ok","timestamp":1685206495057,"user_tz":-120,"elapsed":22,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"0iPmh6s9eOOM","execution_count":7,"outputs":[]},{"cell_type":"markdown","source":["## Regression Models"],"metadata":{"id":"9TPcXVKwp16d"},"id":"9TPcXVKwp16d"},{"cell_type":"code","source":["def grid_search_cv(df):\n","  from sklearn.model_selection import GridSearchCV, cross_validate, train_test_split\n","  from sklearn.metrics import make_scorer, mean_squared_error, r2_score\n","  from sklearn.linear_model import LinearRegression\n","  from sklearn.tree import DecisionTreeRegressor\n","  from sklearn.ensemble import RandomForestRegressor\n","\n","  # Split the data into training and test sets\n","  X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1], df.iloc[:, -1], test_size=0.2, random_state=42)\n","\n","  # Define the list of models to evaluate\n","  models = [\n","      ('Linear Regression', LinearRegression()),\n","      ('Decision Tree', DecisionTreeRegressor()),\n","      ('Random Forest', RandomForestRegressor())\n","  ]\n","\n","  # Define the grid of hyperparameters for each model\n","  param_grid = {\n","      'Linear Regression': {},\n","      'Decision Tree': {'max_depth': [None, 5, 10]},\n","      'Random Forest': {'n_estimators': [100, 200, 300]}\n","  }\n","\n","  # Define the scoring metrics for evaluation\n","  scoring = {\n","      'RMSE': make_scorer(mean_squared_error, squared=False),\n","      'R2': make_scorer(r2_score)\n","  }\n","\n","  # Perform grid search and cross-validation for each model\n","  results = {}\n","  for name, model in models:\n","      grid_search = GridSearchCV(model, param_grid[name], scoring=scoring, refit='RMSE', cv=5)\n","      grid_search.fit(X_train, y_train)\n","      \n","      # Cross-validation scores for all parameter combinations\n","      cv_results = cross_validate(grid_search.best_estimator_, X_train, y_train, scoring=scoring, cv=5)\n","      \n","      results[name] = {\n","          'best_params': grid_search.best_params_,\n","          'best_estimator': grid_search.best_estimator_,\n","          'cv_RMSE': cv_results['test_RMSE'].mean(),\n","          'cv_R2': cv_results['test_R2'].mean()\n","      }\n","\n","  # Print the results for all models and parameter combinations\n","  for name, result in results.items():\n","      print(\"Model:\", name)\n","      print(\"Best Parameters:\", result['best_params'])\n","      print(\"CV RMSE:\", result['cv_RMSE'])\n","      print(\"CV R2:\", result['cv_R2'])\n","      print()\n","\n","  # Train the best model on the entire training dataset\n","  best_model = min(results, key=lambda x: results[x]['cv_RMSE'])\n","  final_model = results[best_model]['best_estimator']\n","  final_model.fit(X_train, y_train)\n","\n","  # Evaluate the performance of the best model on the test set\n","  y_pred = final_model.predict(X_test)\n","  mse = mean_squared_error(y_test, y_pred)\n","  rmse = np.sqrt(mse)\n","  r2 = r2_score(y_test, y_pred)\n","  print(\"Best Model:\", best_model)\n","  print(\"Test RMSE:\", rmse)\n","  print(\"Test R2:\", r2)\n"],"metadata":{"id":"TpBGFm5EikkM","executionInfo":{"status":"ok","timestamp":1685206495058,"user_tz":-120,"elapsed":22,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"TpBGFm5EikkM","execution_count":8,"outputs":[]},{"cell_type":"code","source":["#df = df.drop(columns=['group','project', 'theory']) #'coeval', 'project','theory','group'"],"metadata":{"id":"AxQdRZYFzr-C","executionInfo":{"status":"ok","timestamp":1685206495058,"user_tz":-120,"elapsed":21,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"AxQdRZYFzr-C","execution_count":9,"outputs":[]},{"cell_type":"code","source":["#grid_search_cv(df)"],"metadata":{"id":"MSBnRiSau6O6","executionInfo":{"status":"ok","timestamp":1685206495059,"user_tz":-120,"elapsed":21,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"MSBnRiSau6O6","execution_count":10,"outputs":[]},{"cell_type":"code","source":["def try_regressions(df):\n","\n","  # Step 2: Split the data into features (X) and the objective variable (y)\n","  X = df.iloc[:, :-1]  # All columns except the last one\n","  y = df.iloc[:, -1]   # Last column\n","\n","  # Step 3: Split the data into training and testing sets\n","  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","  # Step 4: Build and evaluate different OLS models\n","  models = []\n","\n","  # Model 1: OLS using statsmodels\n","  model1 = sm.OLS(y_train, sm.add_constant(X_train))\n","  results1 = model1.fit()\n","  models.append(results1)\n","\n","  # Model 2: OLS using scikit-learn (linear regression)\n","  from sklearn.linear_model import LinearRegression\n","  model2 = LinearRegression()\n","  model2.fit(X_train, y_train)\n","  models.append(model2)\n","\n","  # Model 3: OLS using scikit-learn (Ridge regression)\n","  from sklearn.linear_model import Ridge\n","  model3 = Ridge(alpha=1.0)  # You can adjust the regularization parameter (alpha) as needed\n","  model3.fit(X_train, y_train)\n","  models.append(model3)\n","\n","  # Step 5: Evaluate the models on the testing set\n","  for model in models:\n","      if isinstance(model, sm.regression.linear_model.RegressionResultsWrapper):\n","          X_test_with_constant = sm.add_constant(X_test)\n","          y_pred = model.predict(X_test_with_constant)\n","          r2 = model.rsquared\n","      else:\n","          y_pred = model.predict(X_test)\n","          r2 = model.score(X_test, y_test)\n","\n","      # Calculate evaluation metrics (e.g., mean squared error)\n","      mse = np.mean((y_pred - y_test) ** 2)\n","\n","      # Print the evaluation results\n","      print(model)\n","      print(\"Mean Squared Error:\", mse)\n","      print(\"R-squared:\", r2)\n","      print()\n","\n"],"metadata":{"id":"qyWMTe9d7kdQ","executionInfo":{"status":"ok","timestamp":1685206495060,"user_tz":-120,"elapsed":22,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"qyWMTe9d7kdQ","execution_count":11,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.linear_model import LinearRegression, Ridge\n","\n","def try_regressions(df):\n","    # Step 2: Split the data into features (X) and the objective variable (y)\n","    X = df.iloc[:, :-1]  # All columns except the last one\n","    y = df.iloc[:, -1]   # Last column\n","\n","    # Step 3: Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Step 4: Build and evaluate different OLS models\n","    models = []\n","\n","    # Model 1: OLS using scikit-learn (linear regression)\n","    model1 = LinearRegression()\n","    model1.fit(X_train, y_train)\n","    models.append(('Linear Regression', model1))\n","\n","    # Model 2: OLS using scikit-learn (Ridge regression)\n","    model2 = Ridge(alpha=1.0)  # You can adjust the regularization parameter (alpha) as needed\n","    model2.fit(X_train, y_train)\n","    models.append(('Ridge Regression', model2))\n","\n","    # Step 5: Evaluate the models using cross-validation\n","    for name, model in models:\n","        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n","        mse = -scores.mean()\n","        r2 = model.score(X_test, y_test)\n","\n","        # Print the evaluation results\n","        print(name)\n","        print(\"Mean Squared Error:\", mse)\n","        print(\"R-squared:\", r2)\n","        print()\n"],"metadata":{"id":"UmucBH-XASzG","executionInfo":{"status":"ok","timestamp":1685206495060,"user_tz":-120,"elapsed":22,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"UmucBH-XASzG","execution_count":12,"outputs":[]},{"cell_type":"code","source":["import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split, cross_val_score\n","from sklearn.linear_model import LinearRegression, Ridge\n","\n","def try_regressions(df):\n","    # Step 2: Split the data into features (X) and the objective variable (y)\n","    X = df.iloc[:, :-1]  # All columns except the last one\n","    y = df.iloc[:, -1]   # Last column\n","\n","    # Step 3: Split the data into training and testing sets\n","    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","    # Step 4: Build and evaluate different OLS models\n","    models = []\n","\n","    # Model 1: OLS using scikit-learn (linear regression)\n","    model1 = LinearRegression()\n","    model1.fit(X_train, y_train)\n","    models.append(('Linear Regression', model1))\n","\n","    # Model 2: OLS using scikit-learn (Ridge regression)\n","    model2 = Ridge(alpha=1.0)  # You can adjust the regularization parameter (alpha) as needed\n","    model2.fit(X_train, y_train)\n","    models.append(('Ridge Regression', model2))\n","\n","    # Step 5: Evaluate the models using cross-validation\n","    results = {}\n","\n","    for name, model in models:\n","        scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n","        mse = -scores.mean()\n","        r2 = model.score(X_test, y_test)\n","\n","        # Store the evaluation results in a dictionary\n","        results[name] = {'Mean Squared Error': mse, 'R-squared': r2}\n","\n","    return results\n"],"metadata":{"id":"GOMLbr9qDRGN","executionInfo":{"status":"ok","timestamp":1685206495061,"user_tz":-120,"elapsed":21,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"GOMLbr9qDRGN","execution_count":13,"outputs":[]},{"cell_type":"markdown","source":["## Use of Functions"],"metadata":{"id":"d9pT_rns_qjX"},"id":"d9pT_rns_qjX"},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","\n","results = []\n","indexes = []\n","\n","for x in range(0, 5000):\n","    df_test, index = create_random_df(df)\n","    results.append(try_regressions(df_test))\n","    indexes.append(index)\n","\n","data = []\n","\n","for i, result in enumerate(results):\n","    for model_name, metrics in result.items():\n","        r2 = metrics['R-squared']\n","        mse = metrics['Mean Squared Error']\n","        data.append([model_name, r2, mse, indexes[i]])\n","\n","df_results = pd.DataFrame(data, columns=['Model', 'R-squared', 'Mean Squared Error', 'Index'])\n","\n","df_results = df_results.sort_values(by='R-squared', ascending=False)\n","\n","df_results.head(10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":513},"id":"Q0VbRxB_Fyi_","executionInfo":{"status":"ok","timestamp":1685206736559,"user_tz":-120,"elapsed":241519,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}},"outputId":"2fe60f4c-6f99-41dd-a5c3-3ac15d056087"},"id":"Q0VbRxB_Fyi_","execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                  Model  R-squared  Mean Squared Error  \\\n","5596  Linear Regression   0.669857            0.059031   \n","4650  Linear Regression   0.635983            0.037089   \n","772   Linear Regression   0.632904            0.051780   \n","424   Linear Regression   0.618783            0.055156   \n","8198  Linear Regression   0.617097            0.106106   \n","6564  Linear Regression   0.611049            0.036578   \n","6816  Linear Regression   0.603842            0.054127   \n","9536  Linear Regression   0.598687            0.030599   \n","8310  Linear Regression   0.593953            0.041740   \n","5018  Linear Regression   0.587031            0.040421   \n","\n","                                                  Index  \n","5596  [num_turns, indiv_spoken_time_ratio, activity_...  \n","4650  [num_turns, average_turn_duration, activity_en...  \n","772   [num_turns, text_joy, emotionality_avg, activi...  \n","424   [max_words_turn_ratio, num_turns, contribution...  \n","8198  [num_turns, num_turns_ratio, sentiment_avg, ac...  \n","6564  [text_joy, num_turns_ratio, messages_sent, con...  \n","6816  [avg_time_without_speaking, num_turns, activit...  \n","9536  [text_joy, indiv_spoken_time_ratio, contributi...  \n","8310  [num_turns, max_words_turn_ratio, EMOTIONS_Hap...  \n","5018  [num_turns, max_words_turn_ratio, activity_ent...  "],"text/html":["\n","  <div id=\"df-0fb6b877-da13-4a1f-85c7-5aacb5d9151d\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>R-squared</th>\n","      <th>Mean Squared Error</th>\n","      <th>Index</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5596</th>\n","      <td>Linear Regression</td>\n","      <td>0.669857</td>\n","      <td>0.059031</td>\n","      <td>[num_turns, indiv_spoken_time_ratio, activity_...</td>\n","    </tr>\n","    <tr>\n","      <th>4650</th>\n","      <td>Linear Regression</td>\n","      <td>0.635983</td>\n","      <td>0.037089</td>\n","      <td>[num_turns, average_turn_duration, activity_en...</td>\n","    </tr>\n","    <tr>\n","      <th>772</th>\n","      <td>Linear Regression</td>\n","      <td>0.632904</td>\n","      <td>0.051780</td>\n","      <td>[num_turns, text_joy, emotionality_avg, activi...</td>\n","    </tr>\n","    <tr>\n","      <th>424</th>\n","      <td>Linear Regression</td>\n","      <td>0.618783</td>\n","      <td>0.055156</td>\n","      <td>[max_words_turn_ratio, num_turns, contribution...</td>\n","    </tr>\n","    <tr>\n","      <th>8198</th>\n","      <td>Linear Regression</td>\n","      <td>0.617097</td>\n","      <td>0.106106</td>\n","      <td>[num_turns, num_turns_ratio, sentiment_avg, ac...</td>\n","    </tr>\n","    <tr>\n","      <th>6564</th>\n","      <td>Linear Regression</td>\n","      <td>0.611049</td>\n","      <td>0.036578</td>\n","      <td>[text_joy, num_turns_ratio, messages_sent, con...</td>\n","    </tr>\n","    <tr>\n","      <th>6816</th>\n","      <td>Linear Regression</td>\n","      <td>0.603842</td>\n","      <td>0.054127</td>\n","      <td>[avg_time_without_speaking, num_turns, activit...</td>\n","    </tr>\n","    <tr>\n","      <th>9536</th>\n","      <td>Linear Regression</td>\n","      <td>0.598687</td>\n","      <td>0.030599</td>\n","      <td>[text_joy, indiv_spoken_time_ratio, contributi...</td>\n","    </tr>\n","    <tr>\n","      <th>8310</th>\n","      <td>Linear Regression</td>\n","      <td>0.593953</td>\n","      <td>0.041740</td>\n","      <td>[num_turns, max_words_turn_ratio, EMOTIONS_Hap...</td>\n","    </tr>\n","    <tr>\n","      <th>5018</th>\n","      <td>Linear Regression</td>\n","      <td>0.587031</td>\n","      <td>0.040421</td>\n","      <td>[num_turns, max_words_turn_ratio, activity_ent...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fb6b877-da13-4a1f-85c7-5aacb5d9151d')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0fb6b877-da13-4a1f-85c7-5aacb5d9151d button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0fb6b877-da13-4a1f-85c7-5aacb5d9151d');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["df_results.head(5).to_excel(out_file, index=False)"],"metadata":{"id":"gZrLTrNpKP-a","executionInfo":{"status":"ok","timestamp":1685207039780,"user_tz":-120,"elapsed":441,"user":{"displayName":"Álvaro Francisco Gil","userId":"03286819362748434806"}}},"id":"gZrLTrNpKP-a","execution_count":15,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.13"},"colab":{"provenance":[{"file_id":"1vwdjcqEdBtwdLRVemm2obr9-3EqLFird","timestamp":1683651927472},{"file_id":"1hp8Al1PXfv_qks5p7af_ZlBF-qlMhBFt","timestamp":1683646657357}],"toc_visible":true,"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}